{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"profile/","title":"Profile","text":"<p>PDF </p>"},{"location":"profile/#summary","title":"Summary","text":"<p>Aerospace Engineer and PhD in mechanical engineering with expertise in high-performance computing and machine learning. Keen at developing skills in computer vision techniques. A brief summary of expertise:</p> <ul> <li>HPC programming in <code>Python</code>.</li> <li>Machine learning with <code>PyTorch</code>.</li> <li>CFD simulation with <code>OpenFOAM</code>.</li> <li>PIV experimental skills.</li> <li>Cloud computing, GPU computing.</li> <li>Administration of HPC system.</li> </ul>"},{"location":"profile/#technical-skills","title":"Technical skills","text":""},{"location":"profile/#scientific-programming","title":"Scientific programming","text":"<ul> <li>CAD: Blender \u00b7 CATIA</li> <li>CFD: FEniCS \u00b7 Fluent \u00b7 OpenFOAM</li> <li>Programming: C++ \u00b7 MATLAB \u00b7 Python \u00b7 R \u00b7 Shell</li> <li>Python Libraries (HPC): CuPy \u00b7 Cython \u00b7 Dask \u00b7 H5py \u00b7 MPI4py \u00b7 Numba \u00b7 NumPy \u00b7 Pandas \u00b7 SciPy</li> <li>Python Libraries (ML): PyTorch \u00b7 Scikit-learn</li> <li>Python Libraries (Plotting): Dash \u00b7 Matplotlib \u00b7 Scikit-image</li> </ul>"},{"location":"profile/#software-development","title":"Software development","text":"<ul> <li>Automation: Ansible</li> <li>CI/CD: Git (Github, Gitlab) \u00b7 Travis CI</li> <li>Cloud: Amazon AWS (EC2)</li> <li>Container: Docker \u00b7 Kubernetes \u00b7 Sarus \u00b7 Vagrant</li> <li>Database: InfluxDB \u00b7 MariaDB</li> <li>Embedded: Arduino \u00b7 Raspberry Pi \u00b7 NVIDIA Jetson Nano</li> <li>HPC: SLURM</li> <li>Markup / Typesetting: Jinja \u00b7 LaTeX \u00b7 Markdown \u00b7 MkDocs \u00b7 Pandoc \u00b7 Vim</li> <li>Monitoring: Grafana</li> <li>OS: Linux (Arch, Fedora, Ubuntu, Rocky Linux) \u00b7 MacOS \u00b7 Windows</li> <li>Web: CSS \u00b7 HTML5 \u00b7 Nginx</li> </ul>"},{"location":"profile/#academic-professional-experience","title":"Academic &amp; professional experience","text":"<p>Postdoctoral researcher \u2014 Empa\u2003(Z\u00fcrich, Switzerland) June 2019 \u2014 Present</p> <ul> <li>Application of machine learning in quantitative flow visualization.</li> <li>Supervised optical flow algorithms for PIV.</li> <li>Convolutional Neural Networks (CNN) in PyTorch.</li> <li>Additional responsibilities: Deputy Laser safety officer (LSO), deputy data management, Lab HPC support, and fluid tunnel support.</li> </ul> <p>Scientific Assistant \u2014 ETH Z\u00fcrich\u2003(Z\u00fcrich, Switzerland) May 2015 \u2014 May 2019</p> <ul> <li>Numerical and experimental research at Empa.</li> <li>Neutron radiography at Paul Scherrer Institut (PSI).</li> <li>Teaching assistant for Application of CFD in buildings.</li> <li>Supervision of master thesis project: Praharsh Pai Raikar</li> </ul>"},{"location":"profile/#education","title":"Education","text":"Doctor of Sciences (Dr. sc.) \u2014 Mechanical Engineering ETH Z\u00fcrich, Switzerland 2015 \u2014 2019 <p>Thesis: Impact of Vegetation on Urban Microclimate Advisor: Prof. Dr. Jan Carmeliet</p> <ul> <li>Development of a coupled soil-vegetation-air-radiation model in C++ within the OpenFOAM library.</li> <li>Wind tunnel study of flow past model and natural plants using PIV.</li> <li>X-ray tomography of small natural plants and high-performance big data analysis in python (<code>HDF5</code>, <code>scikit-image</code>, <code>dask</code>, <code>numba</code>).</li> </ul> Master of Science (ir.) \u2014 Aerospace Engineering Delft University of Technology, The Netherlands 2011 \u2014 2014 <p>Major: Aerodynamics and Wind Engineering Thesis: Hybrid Eulerian-Lagrangian Vortex Particle Method: Developing a fast and accurate numerical method for the application of Vertical-Axis Wind Turbine (VAWT).  Advisor: Prof. dr. ir. Carlos Sim\u00e3o Ferreira</p> <ul> <li>Development of a high-performance numerical method in python with <code>cython</code> and GPU (CUDA) acceleration.</li> </ul> Bachelor of Science (ir.) \u2014 Aerospace Engineering Delft University of Technology, The Netherlands 2008 \u2014 2011 <p>Minor: Wind energy and Sustainability Thesis: Designing a multi-purpose autonomous aerial monitoring aircraft.</p> <ul> <li>Design a UAV that can cope with severe weather conditions, while performing a variety of sensing and monitoring tasks.</li> </ul>"},{"location":"profile/#languages","title":"Languages","text":"<ul> <li>English (Native)</li> <li>German (Conversational)</li> <li>Malayalam (Fluent)</li> <li>Dutch (Basic)</li> </ul>"},{"location":"profile/#awards","title":"Awards","text":"<ol> <li>Outstanding Oral Presentation at 13th Symposium on Urban Environment, Jan 2017, Seattle, USA</li> <li>Young Best Research Award at 4th International Conference on Countermeasures to Urban Heat Island, May 2016, Singapore.</li> </ol>"},{"location":"profile/#publications-presentations","title":"Publications &amp; Presentations","text":""},{"location":"profile/#journals","title":"Journals","text":"<ol> <li>Manickathan, L., Mucignat, C., Lunati, I. (2022). Kinematic training of convolutional neural networks for particle image velocimetry. Measurement Science and Technology </li> <li>Manickathan, L., Defraeye, T., Carl, S., Richter, H., Allegrini, J., Derome, D., &amp; Carmeliet, J. (2022). A study on diurnal microclimate hysteresis and plant morphology of a Buxus sempervirens using PIV, infrared thermography, and X-ray imaging. Agricultural and Forest Meteorology 313, 108722.  </li> <li>Manickathan, L., Defraeye, T., Allegrini, J., Derome, D., &amp; Carmeliet, J. (2018). Parametric study of the influence of environmental factors and tree properties on the transpirative cooling effect of trees. Agricultural and Forest Meteorology 248, 259-274.  </li> <li>Manickathan, L., Defraeye, T., Allegrini, J., Derome, D., &amp; Carmeliet, J. (2018). Comparative study of flow field and drag coefficient of model and small natural trees in a wind tunnel. Urban Forestry &amp; Urban Greening, 35(December 2017), 230\u2013239.  </li> </ol>"},{"location":"profile/#preprints","title":"Preprints","text":"<ol> <li>Manickathan, L., Defraeye, T., Carl, S., Richter, H., Allegrini, J., Derome, D., &amp; Carmeliet, J. (2019). Unveiling dynamic changes in the diurnal microclimate of a Buxus sempervirens with non-intrusive imaging of flow field, leaf temperature, and plant microstructure. </li> <li>Palha, A., Manickathan, L., Ferreira, C. S., &amp; van Bussel, G. (2015). A hybrid Eulerian-Lagrangian flow solver [Numerical Analysis; Fluid Dynamics]. 27.  </li> </ol>"},{"location":"profile/#manuscripts","title":"Manuscripts","text":"<ul> <li>PhD thesis: Manickathan, L. (2019). Impact of vegetation on urban microclimate. ETH Zurich.  </li> <li>Master thesis: Manickathan, L. (2014). Hybrid Eulerian-Lagrangian Vortex Particle Method. In Msc, Technical University of Delft.  </li> </ul>"},{"location":"profile/#selected-conferences","title":"Selected conferences","text":"<ol> <li>Manickathan, L., Kubilay, A., Defraeye, T., Allegrini, J., Derome, D., &amp; Carmeliet, J.: Integrated CFD vegetation model with soil-plant-air water dynamics for studying the cooling potential of vegetation in an urban street canyon. 10th International Conference on Urban Climate/14th Symposium on the Urban Environment, New York, NY, USA, 6 - 10 August 2018.</li> <li>Manickathan, L., Defraeye, T., Allegrini, J., Derome D., &amp; Carmeliet, J.: Conjugate Vegetation Model for Evaluating Evapotranspirative Cooling in Urban Environment. 97th AMS Annual Meeting, Seattle, WA, USA, 2017.</li> <li>Manickathan, L., Defraeye, T., Allegrini, J., Derome, D., &amp; Carmeliet, J.: Aerodynamic characterization of model vegetation by wind tunnel experiments. 4th International Conference on Countermeasures to Urban Heat Island, Singapore, 2016.</li> </ol>"},{"location":"projects/","title":"Projects","text":"<p> GitHub Stats:</p> <p> </p>"},{"location":"projects/#docs","title":"Docs","text":"<ul> <li> <p>Awesome Fluid Dynamics - A curated list of repositories related to fluid dynamics.</p> <p> </p> </li> <li> <p>lento234.github.io - Personal website hosted at github</p> <p> </p> </li> <li> <p>ML Tutorials - Machine learning tutorials (PyTorch)</p> <p> </p> </li> <li> <p>Python Tutorials - A brief collection of python tutorial</p> <p> </p> </li> </ul>"},{"location":"projects/#devops","title":"Devops","text":"<ul> <li> <p>Homelab - Personal homelab setup</p> <p> </p> </li> <li> <p>Dockerfiles - Repository of private dockerfiles</p> <p> </p> </li> <li> <p>Dotfiles - My personal dotfiles for bash/zsh, vim, tmux, apt, brew.</p> <p> </p> </li> <li> <p>MOTD - Collection of my motd scripts</p> <p> </p> </li> </ul>"},{"location":"projects/#web-apps","title":"Web apps","text":"<ul> <li> <p>SensAI - Sensor-based Atmospheric Intelligence</p> <p> </p> </li> </ul>"},{"location":"projects/#cli-apps","title":"CLI apps","text":"<ul> <li> <p>Wordlebee - A cli wordle word guessing helper bee to solve the wordle puzzle of the day.</p> <p> </p> </li> </ul>"},{"location":"projects/#hobby","title":"Hobby","text":"<ul> <li> <p>Advent of Code 2021 - Advent-of-Code: 2021 Edition</p> <p> </p> </li> </ul>"},{"location":"projects/#library","title":"Library","text":"<ul> <li> <p>pivuq - PIV Uncertainty Quantification.</p> <p> </p> </li> <li> <p>Ragnarok - Ragnarok is a library for solving lattice boltzmann</p> <p> </p> </li> <li> <p>OpenFoam 2.3.x - Custom OpenFOAM Application and src</p> <p></p> </li> </ul>"},{"location":"tools/","title":"Tools","text":""},{"location":"tools/#alternative-front-ends","title":"Alternative Front-Ends","text":"<ul> <li>nitter - Twitter front-end</li> <li>invidious - YouTube front-end</li> </ul>"},{"location":"tools/#references","title":"References","text":"<ul> <li>devhints.io - Devhints \u2014 TL;DR for developer documentation</li> <li>cpp Cheat Sheets - hackingcpp C++ cheat sheet</li> </ul>"},{"location":"tools/#search","title":"Search","text":"<ul> <li>hn.algolia.com - Search Hacker News</li> </ul>"},{"location":"tools/#networking","title":"Networking","text":"<ul> <li>SWITCH Traffic Map - Swiss Map - SWITCHlan Traffic Viewer - SWITCH</li> <li>ipconfig.co - What is my IP address? \u2014 ifconfig.co</li> <li>dnschecker - IP WHOIS Lookup - Lookup an IP Address - DNS Checker</li> <li>dnsdumpster - DNS recon &amp; research, find &amp; lookup dns records</li> <li>spyse - subdomain finder - Finds subdomain</li> </ul>"},{"location":"tools/#coding","title":"Coding","text":"<ul> <li>regex101.com - regex101: build, test, and debug regex</li> <li>URL Decoder/Encoder - URL Decoder/Encoder</li> <li>b64.io - Online base64 file encoder</li> <li>Markdown badges - \ud83d\ude00 Markdown Badges | markdown-badges</li> <li>chmod-calculator.com - Chmod calculator</li> <li>godbolt.org - Compiler explorer</li> </ul>"},{"location":"tools/#design","title":"Design","text":"<ul> <li>Simple Icons - Repository of Free SVG icons for popular brands</li> </ul>"},{"location":"tools/#entertainment","title":"Entertainment","text":"<ul> <li>tunefind.com - tunefind: Find the tune you are looking for</li> <li>ffmpeg command generator - A friend to help you build ffmpeg commands</li> </ul>"},{"location":"tools/#maps","title":"Maps","text":"<ul> <li>lightpollutionmap.info - Light pollution map</li> <li>Kanton Zurich - Abfluss &amp; Wasserstand - Abfluss &amp; Wasserstand | Kanton Z\u00fcrich</li> <li>RS StationView - Earthquake &amp; Earth Monitoring Solutions | Raspberry Shake Map</li> <li>Isochrone train map - How far can you go by train in 5h?</li> </ul>"},{"location":"tools/#aviation-aerospace-astronomy","title":"Aviation, Aerospace, Astronomy","text":"<ul> <li>Live ATC - Live Air Traffic - From their headsets to you</li> <li>Starlink Satellite Map - Find location of all starlink satellites</li> </ul>"},{"location":"wiki/","title":"Wiki, Guides, and Tutorials","text":""},{"location":"wiki/#system","title":"System","text":"<ul> <li>Archlinux wiki - ArchWiki.</li> <li>Digital Ocean Tutorials - Development and sysadmin tutorials.</li> <li>Tanel Poder Consulting - Blog by Tanel Pder.</li> <li>Rocky Linux Documentation - Rocky linux wiki.</li> <li>RPM Fusion - RPM Fusion provides software that the Fedora Project or Red Hat doesn't want to ship.</li> <li>Configuring LUKS - Configuring LUKS: Linux Unified Key Setup.</li> </ul>"},{"location":"wiki/#embedded-systems","title":"Embedded systems","text":"<ul> <li>Jetson Nano wiki - NVIDIA Jetson Nano Wiki</li> <li>PyTorch Container for Jetson and JetPack - Container</li> <li>Nvidia Docker - NVIDIA Docker GitHub</li> <li>PyTorch for Jetson</li> </ul>"},{"location":"wiki/#programming","title":"Programming","text":"<ul> <li>TheAlternative Course Materials - ETHZ gitlab repo of <code>TheAlternative</code> courses.</li> <li>Rstudio Cheat sheets - Rstudio cheat sheet at GitHub.</li> <li>hackingcpp - Learn Contemporary C++ | Concise &amp; Visual Examples | hacking C++</li> </ul>"},{"location":"wiki/#networking","title":"Networking","text":"<ul> <li>UFW Essentials: Common Firewall Rules and Commands</li> <li>Linux as a gateway</li> <li>sssd: Identity management - Open Source Client for Enterprise Identity Management</li> <li>FreeIPA - Open Source Identity Management Solution</li> <li>ctrl.blog - How to alternate ssh port in Fedora</li> <li>Tailscale: How NAT traversal works - A very detailed look at how Tailscale works.</li> </ul>"},{"location":"wiki/#clustering","title":"Clustering","text":"<ul> <li>Ansible - Automation</li> <li>Make your very own Kubernetes cluster with Raspberry PIs</li> <li>Build a Raspberry PI cluster computer</li> <li>Building a Raspberry PI Cluster</li> <li>MpichCluster</li> </ul>"},{"location":"wiki/#writing","title":"Writing","text":"<ul> <li>Scientific writing with markdown</li> <li>Pandoc-crossref guide</li> <li>Markdown cheat sheet</li> </ul>"},{"location":"art/","title":"Art","text":""},{"location":"art/#algorithmic-art","title":"Algorithmic art","text":""},{"location":"blog/CFD/2018-09-01-ragnarok/","title":"Lattice Boltzmann solver: Ragnarok","text":"<p>Ragnarok is an open-source python library for solving lattice boltzmann method.</p> <p> </p> <p>Pip install (directly from git repo):</p> <pre><code>$ pip install git+https://github.com/lento234/ragnarok.git\n</code></pre> <p>Standard</p> In\u00a0[1]: Copied! <pre>import time\nimport numpy as np\nimport math\n</pre> import time import numpy as np import math <p>High performance computing</p> In\u00a0[2]: Copied! <pre>from numba import vectorize, jit\n</pre> from numba import vectorize, jit <p>Plotting</p> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n</pre> import matplotlib.pyplot as plt import matplotlib.animation as animation <p>Lattice boltzmann solver</p> In\u00a0[4]: Copied! <pre>import ragnarok\n</pre> import ragnarok In\u00a0[5]: Copied! <pre>def doublyperiodicshearlayer():\n    delta = 0.05\n    kappa = 80.0\n    u0 = 0.01\n    ux = np.zeros(x.shape)\n    ux[y&lt;=Ny/2.0] = u0*np.tanh(kappa*(y[y&lt;=Ny/2.0]/float(Ny) - 0.25))\n    ux[y&gt;Ny/2.0]  = u0*np.tanh(kappa*(0.75 - y[y&gt;Ny/2.0]/float(Ny)))\n    uy = delta*u0*np.sin(2*np.pi*(x/float(Nx) + 0.25))\n    return ux, uy\n</pre> def doublyperiodicshearlayer():     delta = 0.05     kappa = 80.0     u0 = 0.01     ux = np.zeros(x.shape)     ux[y&lt;=Ny/2.0] = u0*np.tanh(kappa*(y[y&lt;=Ny/2.0]/float(Ny) - 0.25))     ux[y&gt;Ny/2.0]  = u0*np.tanh(kappa*(0.75 - y[y&gt;Ny/2.0]/float(Ny)))     uy = delta*u0*np.sin(2*np.pi*(x/float(Nx) + 0.25))     return ux, uy <p>GR version</p> In\u00a0[6]: Copied! <pre>def plot(t,zlim=(-0.25,0.25)):\n    vortz = curl(solver.u)\n    pygr.surface(vortz, rotation=0, tilt=90,colormap=34,\n                 xlabel='x', ylabel='y', title='vortz - T = {}'.format(t),\n                 zlim=zlim, accelerate=True)\n</pre> def plot(t,zlim=(-0.25,0.25)):     vortz = curl(solver.u)     pygr.surface(vortz, rotation=0, tilt=90,colormap=34,                  xlabel='x', ylabel='y', title='vortz - T = {}'.format(t),                  zlim=zlim, accelerate=True) <p>** MPL version:**</p> In\u00a0[7]: Copied! <pre>def plot_mpl(i):\n    plt.figure('plot')    \n    plt.clf()\n    vortz = curl(solver.u)\n    levels = np.linspace(-0.25,0.25,26)\n    plt.contourf(x,y,vortz,levels,cmap='RdBu_r',extend='both')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('T = %d' % i)\n    plt.colorbar(ticks=levels[::5])\n    plt.axis('scaled')\n    plt.axis([0,Nx,0,Ny])\n    plt.pause(0.1)\n</pre> def plot_mpl(i):     plt.figure('plot')         plt.clf()     vortz = curl(solver.u)     levels = np.linspace(-0.25,0.25,26)     plt.contourf(x,y,vortz,levels,cmap='RdBu_r',extend='both')     plt.xlabel('x')     plt.ylabel('y')     plt.title('T = %d' % i)     plt.colorbar(ticks=levels[::5])     plt.axis('scaled')     plt.axis([0,Nx,0,Ny])     plt.pause(0.1) <p>Velocity norm:</p> In\u00a0[8]: Copied! <pre>@vectorize(['float64(float64,float64)'],target='parallel')\ndef calcnorm(ux,uy):\n    return math.sqrt(ux**2+uy**2)\n</pre> @vectorize(['float64(float64,float64)'],target='parallel') def calcnorm(ux,uy):     return math.sqrt(ux**2+uy**2) <p>Velocity curl - vorticity:</p> In\u00a0[9]: Copied! <pre>@jit\ndef curl(u):\n    dudx,dudy = np.gradient(u[0], 1.0/Nx,1.0/Ny)\n    dvdx,dvdy = np.gradient(u[1], 1.0/Nx,1.0/Ny)\n    return dvdx - dudy\n</pre> @jit def curl(u):     dudx,dudy = np.gradient(u[0], 1.0/Nx,1.0/Ny)     dvdx,dvdy = np.gradient(u[1], 1.0/Nx,1.0/Ny)     return dvdx - dudy <p>Simulation parameters</p> In\u00a0[10]: Copied! <pre>Re = 30000 # Reynolds number\n# T = 20000 # Number of time steps \nT = 20000 # Number of time steps \nU = 0.1 # Lattice velocity\n\nNx = 100 # Number of lattice in x-dir\nNy = 100 # Number of lattice in y-dir\n</pre> Re = 30000 # Reynolds number # T = 20000 # Number of time steps  T = 20000 # Number of time steps  U = 0.1 # Lattice velocity  Nx = 100 # Number of lattice in x-dir Ny = 100 # Number of lattice in y-dir <p>Postprocessing parameters</p> In\u00a0[11]: Copied! <pre># Flags\napply_bc = True\nplot_step = 100\nplot_save = False\nplot_flag = True\n</pre> # Flags apply_bc = True plot_step = 100 plot_save = False plot_flag = True <p>Initialze the 2D NS solver:</p> In\u00a0[12]: Copied! <pre>solver = ragnarok.NavierStokes2D(U=U, Re=Re, Nx=Nx, Ny=Ny)\n</pre> solver = ragnarok.NavierStokes2D(U=U, Re=Re, Nx=Nx, Ny=Ny) <pre>nu = 0.000333\nbeta = 0.998004\nomega = 1.996008\n</pre> <p>Reference parameters:</p> In\u00a0[13]: Copied! <pre># Get parameters\nL = solver.L\nU = solver.U\nnu = solver.nu\nNx = solver.Nx\nNy = solver.Ny\ncs = solver.cs\nx = solver.x[0]\ny = solver.x[1]\n</pre> # Get parameters L = solver.L U = solver.U nu = solver.nu Nx = solver.Nx Ny = solver.Ny cs = solver.cs x = solver.x[0] y = solver.x[1] <p>Assign the initial condition:</p> In\u00a0[14]: Copied! <pre># Setup initial conditions (Doubly periodic shear layer)\nux, uy = doublyperiodicshearlayer()\n</pre> # Setup initial conditions (Doubly periodic shear layer) ux, uy = doublyperiodicshearlayer() <p>Initialize the population:</p> In\u00a0[15]: Copied! <pre>solver.initialize(ux=ux,uy=uy)\n</pre> solver.initialize(ux=ux,uy=uy) <p>** Plot initial condition **</p> In\u00a0[17]: Copied! <pre>plot_mpl(0)\n</pre> plot_mpl(0) In\u00a0[18]: Copied! <pre>fig, ax = plt.subplots()\n\nims = []\nfor t in range(T+1):\n    if t==1: # for JIT\n        startTime = time.time()\n    \n    # Plot\n    if plot_flag and t % plot_step == 0:\n        vortz = curl(solver.u)\n        im = ax.imshow(vortz, vmin=-0.25, vmax=0.25, cmap='RdBu_r')\n        ims.append([im])\n\n    # Step 1: Streaming / advection step: f'_i(x) &lt;- f^n_i(x-c_i)\n    solver.stream()\n    \n    # Step 2: Apply boundary condition\n    solver.apply_periodic()\n    \n    # Step 3: Relaxation / collision step: f^{n+1}_i(x) &lt;- f'_i + \\alpha\\beta [f^{eq}'_i(x,t) - f'_i(x,t)]\n    solver.relax()\n    \n    if solver.rho.min() &lt;= 0.:\n        print('Density is negative!')\n        break\n\n# Done\nduration = time.time()-startTime\nprint('Total time: {:3g} sec for {:d} steps, {:3g} ms/step'.format(duration, T, duration/T*1000))\n</pre> fig, ax = plt.subplots()  ims = [] for t in range(T+1):     if t==1: # for JIT         startTime = time.time()          # Plot     if plot_flag and t % plot_step == 0:         vortz = curl(solver.u)         im = ax.imshow(vortz, vmin=-0.25, vmax=0.25, cmap='RdBu_r')         ims.append([im])      # Step 1: Streaming / advection step: f'_i(x) &lt;- f^n_i(x-c_i)     solver.stream()          # Step 2: Apply boundary condition     solver.apply_periodic()          # Step 3: Relaxation / collision step: f^{n+1}_i(x) &lt;- f'_i + \\alpha\\beta [f^{eq}'_i(x,t) - f'_i(x,t)]     solver.relax()          if solver.rho.min() &lt;= 0.:         print('Density is negative!')         break  # Done duration = time.time()-startTime print('Total time: {:3g} sec for {:d} steps, {:3g} ms/step'.format(duration, T, duration/T*1000))  <pre>Total time: 9.13418 sec for 20000 steps, 0.456709 ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre>ani = animation.ArtistAnimation(fig, ims, interval=10, repeat_delay=1000)\nani.save('animation.mp4')\n</pre> ani = animation.ArtistAnimation(fig, ims, interval=10, repeat_delay=1000) ani.save('animation.mp4') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"blog/CFD/2018-09-01-ragnarok/#lattice-boltzmann-solver-ragnarok","title":"Lattice Boltzmann solver: Ragnarok\u00b6","text":"<p>Last updated: September 1, 2018</p>"},{"location":"blog/CFD/2018-09-01-ragnarok/#doubly-periodic-shear-layer","title":"Doubly-periodic shear layer\u00b6","text":"<p>A 2D NS problem with a doubly-period shear layer initial condition.</p> <p>** Lattice Boltzmann method **</p> <p>A simple lattice Boltzmann Bhatnagar-Gross-Krook (LBGK) model is used, given in discrete form as: \\begin{equation} f_i \\left(\\mathbf{x} + \\mathbf{c}_i, t+1\\right) - f_i \\left(\\mathbf{x}, t\\right) = \\alpha \\beta \\left(f_i^{eq} - f_i\\right) \\end{equation}</p> <p>where $\\alpha = 2$, $\\beta = \\left(2\\nu/c_s^2 +1 \\right)^{-1}$, $f_i$ is the population of discrete velocities $\\mathbf{c}_i$ and $f_i^{eq}$ is the equilibrium population. The local macroscopic (i.e. density and momentum) is defined as:</p> \\begin{equation} \\rho = \\Sigma_i f_i \\end{equation}<p>and \\begin{equation} \\rho \\mathbf{u} = \\Sigma_i \\mathbf{c}_i f_i \\end{equation}</p> <p>The present LBM model uses D2Q9 lattice, discretizing the velocity spaces with 9 population function for simulating 2D-dimensional flow. The associated lattice velocites $[c_x, c_y]^T$ and lattice weights $W$ are:</p> \\begin{equation} \\left[\\begin{array}{c}     c_x\\\\c_y     \\end{array} \\right]     =     \\left[ \\begin{array}{ccccccccc}     0 &amp; 1 &amp; 0 &amp; -1 &amp; 0 &amp; 1 &amp; -1 &amp; -1 &amp; 1\\\\      0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 &amp; 1 &amp; 1 &amp; -1 &amp; -1\\\\      \\end{array} \\right] \\end{equation}<p>and \\begin{equation} W =  \\left[ \\begin{array}{ccccccccc} \\frac{4}{9} &amp; \\frac{1}{9} &amp; \\frac{1}{9} &amp; \\frac{1}{9}&amp; \\frac{1}{9} &amp; \\frac{1}{36} &amp; \\frac{1}{36}  &amp; \\frac{1}{36}  &amp; \\frac{1}{36} \\\\  \\end{array} \\right] \\end{equation}</p> <p>The equilibrium population $f_i^{eq}$ is determined from local conservations: \\begin{equation} f_i^{eq} = \\rho W_i \\left(2 - \\sqrt{1 + 3 u_x^2}\\right) \\left(2 - \\sqrt{1 + 3 u_y^2}\\right) \\\\ \\left(\\frac{2u_x- \\sqrt{1 + 3 u_x^2}}{1 - u_x}\\right)^{c_{x,i}} \\left(\\frac{2u_y- \\sqrt{1 + 3 u_y^2}}{1 - u_y}\\right)^{c_{y,i}} \\end{equation}</p> <p>The discrete LBM is split into two operations: advection (streaming) and relaxtion (collision) step.</p>"},{"location":"blog/CFD/2018-09-01-ragnarok/#import-modules","title":"Import Modules\u00b6","text":""},{"location":"blog/CFD/2018-09-01-ragnarok/#initial-condition","title":"Initial condition\u00b6","text":""},{"location":"blog/CFD/2018-09-01-ragnarok/#plotting-function","title":"Plotting function\u00b6","text":""},{"location":"blog/CFD/2018-09-01-ragnarok/#post-processing-functions","title":"Post-processing functions\u00b6","text":""},{"location":"blog/CFD/2018-09-01-ragnarok/#settings","title":"Settings\u00b6","text":""},{"location":"blog/CFD/2018-09-01-ragnarok/#solver","title":"Solver\u00b6","text":""},{"location":"blog/CFD/2018-09-01-ragnarok/#initial-conditions","title":"Initial conditions\u00b6","text":"<p>The doubly periodic shear layer (DPSL) describes the case of roll-up of two anti-parallel shear layers within a periodic square domain. The initial condition is given as:</p> \\begin{align} u_x &amp;= \\left\\{  \\begin{array}{l} u_0 \\tanh \\left[\\kappa \\left(\\frac{y}{N} - \\frac{1}{4}\\right) \\right], y \\le N/2, \\\\ u_0 \\tanh \\left(\\kappa \\left(\\frac{3}{4} - \\frac{y}{N}\\right) \\right), y &gt; N/2, \\\\ \\end{array} \\right.\\\\ \\\\ u_y &amp;= \\delta \\sin \\left[ 2 \\pi  \\left(\\frac{x}{N} + \\frac{1}{4} \\right)\\right]. \\end{align}"},{"location":"blog/CFD/2018-09-01-ragnarok/#time-stepping","title":"Time stepping\u00b6","text":"<p>The simulation parameters are $\\mathrm{Re} = (U L)/\\nu = 30\\ 000$, $\\delta = 0.05$, $\\kappa = 80$, $L = N = N_x = N_y = 100$ and $U=0.1$, providing a $\\beta = 0.9980$. The vorticity of the flow is defined as $\\omega = \\nabla \\times \\mathbf{u}$ and in 2D with $\\mathbf{u} = (u_x,u_y)^T$, it is given as: \\begin{equation} \\omega = \\frac{\\partial v}{\\partial x} - \\frac{\\partial u}{\\partial y} \\end{equation}</p> <p>Simulation Algorithm:</p> <ol> <li><code>stream</code>: Streaming / advection step: $f'_i(x) \\leftarrow f^n_i(x-c_i)$</li> <li><code>apply_periodic</code>: Apply periodic boundary condition</li> <li><code>relax</code>: Relaxation / collision step: $f^{n+1}_i(x) \\leftarrow f'_i  + \\alpha\\beta \\left[f'^{eq}_i(x,t) - f'_i(x,t)\\right]$</li> </ol>"},{"location":"blog/CFD/2018-09-01-ragnarok/#save-animation","title":"Save animation\u00b6","text":""},{"location":"blog/CFD/2022-03-03-random-irrotational-flow/","title":"Irrotational random flow","text":"<p>Setup</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport skimage.filters\nimport scipy.ndimage\nimport scipy.sparse\n\n# Plotting\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport proplot as pplt\n\n# Lima\nimport lima\n</pre> import numpy as np import skimage.filters import scipy.ndimage import scipy.sparse  # Plotting import matplotlib as mpl import matplotlib.pyplot as plt import proplot as pplt  # Lima import lima In\u00a0[2]: Copied! <pre>lima.plot.init_mpl_style()\n</pre> lima.plot.init_mpl_style() In\u00a0[3]: Copied! <pre>debug = True\n</pre> debug = True In\u00a0[4]: Copied! <pre>subplotgrid = [  \n    [1, 1, 2, 2, 3, 3],\n    [0, 4, 4, 5, 5, 0],\n]\n</pre> subplotgrid = [       [1, 1, 2, 2, 3, 3],     [0, 4, 4, 5, 5, 0], ] <p>Functions</p> In\u00a0[5]: Copied! <pre>def vortZ(u, v):\n    dudy, dudx = np.gradient(u)\n    dvdy, dvdx = np.gradient(v)\n    return dvdx - dudy\n\ndef divUV(u, v):\n    dudy, dudx = np.gradient(u)\n    dvdy, dvdx = np.gradient(v)\n    return dudx + dvdy\n\ndef random_dataset(vscale=1.0, height=256, width=256, filter_size=5, seed=None):\n    if seed:\n        np.random.seed(seed)\n    # Coordinates\n    x, y = np.meshgrid(np.arange(height, dtype='float32'),\n                       np.arange(width, dtype='float32'))\n\n    #u, v = np.random.rand(2, height, width).astype('float32') - 0.5\n    u, v = np.random.uniform(-1, 1, size=(2, height, width)).astype('float32')\n    u = skimage.filters.gaussian(u, filter_size, mode='reflect')\n    v = skimage.filters.gaussian(v, filter_size, mode='reflect')\n    u = u/np.abs(u).max() * vscale\n    v = v/np.abs(v).max() * vscale\n    # Parameters\n    #print(np.max(u), np.max(v))\n    return x, y, u, v\n\ndef quiver(ax, x, y, u, v, skip=1, *args, **kwargs):\n    return ax.quiver(\n        x[::skip, ::skip], y[::skip, ::skip], u[::skip, ::skip], v[::skip, ::skip],\n        *args, **kwargs\n    )\n\nnorm = lambda u,v: np.sqrt(u**2 + v**2)\n</pre> def vortZ(u, v):     dudy, dudx = np.gradient(u)     dvdy, dvdx = np.gradient(v)     return dvdx - dudy  def divUV(u, v):     dudy, dudx = np.gradient(u)     dvdy, dvdx = np.gradient(v)     return dudx + dvdy  def random_dataset(vscale=1.0, height=256, width=256, filter_size=5, seed=None):     if seed:         np.random.seed(seed)     # Coordinates     x, y = np.meshgrid(np.arange(height, dtype='float32'),                        np.arange(width, dtype='float32'))      #u, v = np.random.rand(2, height, width).astype('float32') - 0.5     u, v = np.random.uniform(-1, 1, size=(2, height, width)).astype('float32')     u = skimage.filters.gaussian(u, filter_size, mode='reflect')     v = skimage.filters.gaussian(v, filter_size, mode='reflect')     u = u/np.abs(u).max() * vscale     v = v/np.abs(v).max() * vscale     # Parameters     #print(np.max(u), np.max(v))     return x, y, u, v  def quiver(ax, x, y, u, v, skip=1, *args, **kwargs):     return ax.quiver(         x[::skip, ::skip], y[::skip, ::skip], u[::skip, ::skip], v[::skip, ::skip],         *args, **kwargs     )  norm = lambda u,v: np.sqrt(u**2 + v**2) In\u00a0[6]: Copied! <pre>def construct_LHS(nx, ny, h=1):\n    n = nx * ny \n    B = np.zeros((5, n))\n\n    for i in range(ny):\n        for j in range(nx):\n            k = j*nx + i\n            if i == 0:\n                if j == 0:\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h)\n                    B[3, k+1]  = -2*h/(h + h)\n                    B[4, k+nx] = -2*h/(h + h)\n                elif j == nx-1:\n                    B[0, k-nx] = -2*h/(h + h)\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h)\n                    B[3, k+1]  = -2*h/(h + h)\n                else:\n                    B[0, k-nx] = -2*h/(h + h)\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)\n                    B[3, k+1]  = -2*h/(h + h)\n                    B[4, k+nx] = -2*h/(h + h)\n            elif i == nx-1:\n                if j == 0:\n                    B[1, k-1]  = -2*h/(h + h)\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h)\n                    B[4, k+nx] = -2*h/(h + h)\n                elif j == nx-1:\n                    B[0, k-nx] = -2*h/(h + h)\n                    B[1, k-1]  = -2*h/(h + h)\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h)\n                else:\n                    B[0, k-nx] = -2*h/(h + h)\n                    B[1, k-1]  = -2*h/(h + h)\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)\n                    B[4, k+nx] = -2*h/(h + h)\n            elif j == 0:\n                if ( i &gt; 0 and i &lt; nx-1 ):\n                    B[1, k-1]  = -2*h/(h + h)\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)\n                    B[3, k+1]  = -2*h/(h + h)\n                    B[4, k+nx] = -2*h/(h + h)\n            elif j == nx-1:\n                if ( i &gt; 0 and i &lt; nx-1 ):\n                    B[0, k-nx] = -2*h/(h + h)\n                    B[1, k-1]  = -2*h/(h + h)\n                    B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)\n                    B[3, k+1]  = -2*h/(h + h)\n            else:\n                B[0, k-nx]     = -2*h/(h + h)\n                B[1, k-1]      = -2*h/(h + h)\n                B[2, k]        =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)\n                B[3, k+1]      = -2*h/(h + h)\n                B[4, k+nx]     = -2*h/(h + h)\n    \n    # Diagonal indices\n    diags = np.array([-nx, -1, 0, 1, nx])\n\n    # Construct sparse diagonal matrix\n    L = scipy.sparse.spdiags(B, diags, n, n).tocsr()\n    return L\n\ndef construct_RHS(u, v):\n    f = -divUV(u, v)\n    return f.ravel()\n\ndef solve_poisson_equation(u, v, L=None, debug=False, maxiter=100):\n    if L is None:\n        L = construct_LHS(u.shape[0], u.shape[1])\n    f = construct_RHS(u, v)\n    # Solve using gmres\n    phi, info = scipy.sparse.linalg.gmres(L, f, maxiter=maxiter)\n    if debug:\n        print(f\"Residual: {np.sum(np.abs(L.dot(phi) - f))}\")\n    phi = phi.reshape(u.shape[0], u.shape[1])\n    return phi\n    \ndef calculate_irrotational_flow(u, v, L=None, debug=False, maxiter=100):\n    # Solve poisson equation: $\\nabla^2 \\phi = -\\nabla \\cdot u$\n    phi = solve_poisson_equation(u, v, L, debug, maxiter)\n    \n    # Calculate irrotation flow\n    v_phi, u_phi = np.gradient(phi)\n    \n    return u_phi, v_phi\n</pre> def construct_LHS(nx, ny, h=1):     n = nx * ny      B = np.zeros((5, n))      for i in range(ny):         for j in range(nx):             k = j*nx + i             if i == 0:                 if j == 0:                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h)                     B[3, k+1]  = -2*h/(h + h)                     B[4, k+nx] = -2*h/(h + h)                 elif j == nx-1:                     B[0, k-nx] = -2*h/(h + h)                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h)                     B[3, k+1]  = -2*h/(h + h)                 else:                     B[0, k-nx] = -2*h/(h + h)                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)                     B[3, k+1]  = -2*h/(h + h)                     B[4, k+nx] = -2*h/(h + h)             elif i == nx-1:                 if j == 0:                     B[1, k-1]  = -2*h/(h + h)                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h)                     B[4, k+nx] = -2*h/(h + h)                 elif j == nx-1:                     B[0, k-nx] = -2*h/(h + h)                     B[1, k-1]  = -2*h/(h + h)                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h)                 else:                     B[0, k-nx] = -2*h/(h + h)                     B[1, k-1]  = -2*h/(h + h)                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)                     B[4, k+nx] = -2*h/(h + h)             elif j == 0:                 if ( i &gt; 0 and i &lt; nx-1 ):                     B[1, k-1]  = -2*h/(h + h)                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)                     B[3, k+1]  = -2*h/(h + h)                     B[4, k+nx] = -2*h/(h + h)             elif j == nx-1:                 if ( i &gt; 0 and i &lt; nx-1 ):                     B[0, k-nx] = -2*h/(h + h)                     B[1, k-1]  = -2*h/(h + h)                     B[2, k]    =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)                     B[3, k+1]  = -2*h/(h + h)             else:                 B[0, k-nx]     = -2*h/(h + h)                 B[1, k-1]      = -2*h/(h + h)                 B[2, k]        =  2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h) + 2*h/(h + h)                 B[3, k+1]      = -2*h/(h + h)                 B[4, k+nx]     = -2*h/(h + h)          # Diagonal indices     diags = np.array([-nx, -1, 0, 1, nx])      # Construct sparse diagonal matrix     L = scipy.sparse.spdiags(B, diags, n, n).tocsr()     return L  def construct_RHS(u, v):     f = -divUV(u, v)     return f.ravel()  def solve_poisson_equation(u, v, L=None, debug=False, maxiter=100):     if L is None:         L = construct_LHS(u.shape[0], u.shape[1])     f = construct_RHS(u, v)     # Solve using gmres     phi, info = scipy.sparse.linalg.gmres(L, f, maxiter=maxiter)     if debug:         print(f\"Residual: {np.sum(np.abs(L.dot(phi) - f))}\")     phi = phi.reshape(u.shape[0], u.shape[1])     return phi      def calculate_irrotational_flow(u, v, L=None, debug=False, maxiter=100):     # Solve poisson equation: $\\nabla^2 \\phi = -\\nabla \\cdot u$     phi = solve_poisson_equation(u, v, L, debug, maxiter)          # Calculate irrotation flow     v_phi, u_phi = np.gradient(phi)          return u_phi, v_phi In\u00a0[7]: Copied! <pre>filter_size = 5\nvscale = 1\nheight = width = 64\n</pre> filter_size = 5 vscale = 1 height = width = 64 In\u00a0[8]: Copied! <pre># Random dist.\nnp.random.seed(234)\n\nx, y, _,_ = random_dataset(vscale=1, height=height, width=width, filter_size=filter_size)\nu, v = np.random.uniform(-1, 1, size=(2, height, width)).astype('float32')\n\n# Filtered\nuf = skimage.filters.gaussian(u, filter_size, mode=\"reflect\")#, preserve_range=True) \nvf = skimage.filters.gaussian(v, filter_size, mode=\"reflect\")#, preserve_range=True)\nuf = uf/np.abs(uf).max() * vscale\nvf = vf/np.abs(vf).max() * vscale\n# Scaled\nus = uf\nvs = vf\n</pre> # Random dist. np.random.seed(234)  x, y, _,_ = random_dataset(vscale=1, height=height, width=width, filter_size=filter_size) u, v = np.random.uniform(-1, 1, size=(2, height, width)).astype('float32')  # Filtered uf = skimage.filters.gaussian(u, filter_size, mode=\"reflect\")#, preserve_range=True)  vf = skimage.filters.gaussian(v, filter_size, mode=\"reflect\")#, preserve_range=True) uf = uf/np.abs(uf).max() * vscale vf = vf/np.abs(vf).max() * vscale # Scaled us = uf vs = vf In\u00a0[9]: Copied! <pre>fig = pplt.figure(refwidth='1.8', span=False)\naxes = fig.subplots(subplotgrid)\n\ns = 5\n# u\nax = axes[0]\nim = ax.imshow(us,  interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\nax.format(title=r\"U-Velocity: $u$\")\n\n# v\nax = axes[1]\nim = ax.imshow(vs,  interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\nax.format(title=r\"V-Velocity: $v$\")\n\n# |u| \nax = axes[2]\nim = ax.imshow((us**2 + vs**2)**0.5,  interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\nquiver(ax, x, y, us, vs, skip=2, color='k', scale=s)\nax.format(title=r\"Velocity mag.: $|u|$\")\n\n# vorticity |u| \nax = axes[3]\nim = ax.imshow(np.abs(vortZ(us, vs)), interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\nax.format(title=fr\"Vorticity mag.: $|\\nabla \\times u|$ (sum={np.abs(vortZ(us, vs)).sum():2g})\")\nax.streamplot(x, y, us, vs, c='k', lw=0.5)\nax.axis([0, height, 0, width])\n\n# divergence |u| \nax = axes[4]\nim = ax.imshow(divUV(us, vs), interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\nax.format(title=r\"Divergence: $\\nabla \\cdot u$\")\n\n# Quiver\n\n# # Format\naxes.format(\n    abc='(a)', abcloc='ul', abcbbox=True,\n    xlabel='$x$ (px)', ylabel='$y$ (px)',\n    suptitle='Pure random vector field',\n)\n</pre> fig = pplt.figure(refwidth='1.8', span=False) axes = fig.subplots(subplotgrid)  s = 5 # u ax = axes[0] im = ax.imshow(us,  interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') ax.format(title=r\"U-Velocity: $u$\")  # v ax = axes[1] im = ax.imshow(vs,  interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') ax.format(title=r\"V-Velocity: $v$\")  # |u|  ax = axes[2] im = ax.imshow((us**2 + vs**2)**0.5,  interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') quiver(ax, x, y, us, vs, skip=2, color='k', scale=s) ax.format(title=r\"Velocity mag.: $|u|$\")  # vorticity |u|  ax = axes[3] im = ax.imshow(np.abs(vortZ(us, vs)), interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') ax.format(title=fr\"Vorticity mag.: $|\\nabla \\times u|$ (sum={np.abs(vortZ(us, vs)).sum():2g})\") ax.streamplot(x, y, us, vs, c='k', lw=0.5) ax.axis([0, height, 0, width])  # divergence |u|  ax = axes[4] im = ax.imshow(divUV(us, vs), interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') ax.format(title=r\"Divergence: $\\nabla \\cdot u$\")  # Quiver  # # Format axes.format(     abc='(a)', abcloc='ul', abcbbox=True,     xlabel='$x$ (px)', ylabel='$y$ (px)',     suptitle='Pure random vector field', ) <p>Solve discrete poisson equation</p> <p>The 2D poisson equation is: $$ \\nabla^2 \\phi = f $$ or in 2D cartesian: $$ \\frac{\\partial^2 \\phi}{\\partial x^2} + \\frac{\\partial^2 \\phi}{\\partial y^2} = f $$</p> <p>In discretize form (central): $$ \\frac{\\phi_{i+1,j} - 2\\phi_{i,j} + \\phi_{i-1,j}}{\\Delta x^2} + \\frac{\\phi_{i,j+1} - 2\\phi_{i,j} + \\phi_{i,j-1}}{\\Delta y^2} = f_{i,j} $$</p> <p>Define the discrete Laplacian, i.e., the Laplacian matrix $L$, we then need to solve the system of equation: $$ L \\phi = f $$</p> In\u00a0[10]: Copied! <pre>nx, ny = us.shape\nL = construct_LHS(nx, ny)\n</pre> nx, ny = us.shape L = construct_LHS(nx, ny) <p>Condition number</p> In\u00a0[11]: Copied! <pre>if debug:\n    print(f\"Condition number: {np.linalg.cond(L.todense())}!!!\")\n</pre> if debug:     print(f\"Condition number: {np.linalg.cond(L.todense())}!!!\") <pre>Condition number: 1.1483591666066174e+16!!!\n</pre> In\u00a0[12]: Copied! <pre>if debug:\n    fig = pplt.figure()\n    ax = fig.gca()\n    im = ax.matshow(L.toarray(), cmap='turbo')\n    ax.colorbar(im)\n    ax.axis([100, 0, 0, 100])\n</pre> if debug:     fig = pplt.figure()     ax = fig.gca()     im = ax.matshow(L.toarray(), cmap='turbo')     ax.colorbar(im)     ax.axis([100, 0, 0, 100]) In\u00a0[13]: Copied! <pre>%%time\nmaxiter = 200\nu_phi, v_phi = calculate_irrotational_flow(us, vs, L, debug=debug, maxiter=maxiter)\n</pre> %%time maxiter = 200 u_phi, v_phi = calculate_irrotational_flow(us, vs, L, debug=debug, maxiter=maxiter) <pre>Residual: 6.324544840488443\nCPU times: user 847 ms, sys: 20.1 ms, total: 867 ms\nWall time: 434 ms\n</pre> <p>Inspect vorticity</p> In\u00a0[14]: Copied! <pre>fig = pplt.figure(refwidth='1.8', span=False)\naxes = fig.subplots(subplotgrid)\n\ns = 5\n# u\nax = axes[0]\nim = ax.imshow(u_phi,  interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\n# quiver(ax, x, y, u_phi, v_phi, skip=2, color='k', scale=s)\nax.format(title=r\"U-Velocity: $u$\")\n\n# v\nax = axes[1]\nim = ax.imshow(v_phi,  interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\n# quiver(ax, x, y, u_phi, v_phi, skip=2, color='k', scale=s)\nax.format(title=r\"V-Velocity: $v$\")\n\n# |u| \nax = axes[2]\nim = ax.imshow((u_phi**2 + v_phi**2)**0.5,  interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\nquiver(ax, x, y, u_phi, v_phi, skip=2, color='k', scale=s)\nax.format(title=r\"Velocity mag.: $|u|$\")\n# ax.streamplot(x, y, u_phi, v_phi, c='k', lw=0.5)\n# ax.axis([0, height, 0, width])\n\n# vorticity |u| \nax = axes[3]\nim = ax.imshow(np.abs(vortZ(u_phi, v_phi)), interpolation='none')\ncb = ax.colorbar(im, width='0.75em')\nax.format(title=fr\"Vorticity mag.: $|\\nabla \\times u|$ (sum={np.abs(vortZ(u_phi, v_phi)).sum():2g})\")\n\n# divergence |u| \nax = axes[4]\nim = ax.imshow(divUV(u_phi, v_phi), interpolation='none', cmap='turbo')\ncb = ax.colorbar(im, width='0.75em')\nax.format(title=r\"Divergence: $\\nabla \\cdot u$\")\n# ax.axis([0,64,0,64])\n\n# Quiver\n\n# # Format\naxes.format(\n    abc='(a)', abcloc='ul', abcbbox=True,\n    xlabel='$x$ (px)', ylabel='$y$ (px)',\n    suptitle='Irrotatonal random vector field',\n)\n</pre> fig = pplt.figure(refwidth='1.8', span=False) axes = fig.subplots(subplotgrid)  s = 5 # u ax = axes[0] im = ax.imshow(u_phi,  interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') # quiver(ax, x, y, u_phi, v_phi, skip=2, color='k', scale=s) ax.format(title=r\"U-Velocity: $u$\")  # v ax = axes[1] im = ax.imshow(v_phi,  interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') # quiver(ax, x, y, u_phi, v_phi, skip=2, color='k', scale=s) ax.format(title=r\"V-Velocity: $v$\")  # |u|  ax = axes[2] im = ax.imshow((u_phi**2 + v_phi**2)**0.5,  interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') quiver(ax, x, y, u_phi, v_phi, skip=2, color='k', scale=s) ax.format(title=r\"Velocity mag.: $|u|$\") # ax.streamplot(x, y, u_phi, v_phi, c='k', lw=0.5) # ax.axis([0, height, 0, width])  # vorticity |u|  ax = axes[3] im = ax.imshow(np.abs(vortZ(u_phi, v_phi)), interpolation='none') cb = ax.colorbar(im, width='0.75em') ax.format(title=fr\"Vorticity mag.: $|\\nabla \\times u|$ (sum={np.abs(vortZ(u_phi, v_phi)).sum():2g})\")  # divergence |u|  ax = axes[4] im = ax.imshow(divUV(u_phi, v_phi), interpolation='none', cmap='turbo') cb = ax.colorbar(im, width='0.75em') ax.format(title=r\"Divergence: $\\nabla \\cdot u$\") # ax.axis([0,64,0,64])  # Quiver  # # Format axes.format(     abc='(a)', abcloc='ul', abcbbox=True,     xlabel='$x$ (px)', ylabel='$y$ (px)',     suptitle='Irrotatonal random vector field', )"},{"location":"blog/CFD/2022-03-03-random-irrotational-flow/#irrotational-random-flow","title":"Irrotational random flow\u00b6","text":"<p>Last updated: March 3, 2022</p>"},{"location":"blog/CFD/2022-03-03-random-irrotational-flow/#pure-random-flow","title":"Pure-random flow\u00b6","text":""},{"location":"blog/CFD/2022-03-03-random-irrotational-flow/#rotational-and-irrotational-component","title":"Rotational and irrotational component\u00b6","text":""},{"location":"blog/CFD/2022-03-03-random-irrotational-flow/#irrotational-flow","title":"Irrotational Flow\u00b6","text":"<ol> <li>Perform helmholtz decomposition:</li> </ol> $$ u = -\\nabla \\phi + \\nabla \\times \\psi $$<ol> <li>Construct poisson equation by taking divergence of velocity:</li> </ol> $$ \\nabla \\cdot u = -\\nabla^2 \\phi \\equiv f $$<ol> <li>Solve poisson equation using iterative method (relaxation method) or directly.</li> <li>Calculate irrotation velocity:</li> </ol> $$ u_{\\phi} = -\\nabla \\phi $$"},{"location":"blog/CFD/2022-03-03-random-irrotational-flow/#construct-the-sparse-l-matrix-lhs","title":"Construct the Sparse L matrix (LHS)\u00b6","text":""},{"location":"blog/CFD/2022-03-03-random-irrotational-flow/#calculate-irrotational-velocity","title":"Calculate irrotational velocity\u00b6","text":"<p>The irrotation velocity component is defined as: $$ u_{\\phi} = -\\nabla \\phi $$</p> <p>where $$ \\begin{aligned} u_{x,\\phi} &amp;= \\frac{\\partial \\phi}{\\partial x}\\\\ u_{y,\\phi} &amp;= \\frac{\\partial \\phi}{\\partial y} \\end{aligned} $$</p>"},{"location":"blog/HPC/2021-04-01-h5py-parallel/","title":"Installing h5py with Parallel HDF5","text":"<p>Last updated: April 1, 2021</p> <p>The following guide is if you want to install h5py with parallel (mpi) IO features. Therefore, h5py also requires a system-mpi linked <code>mpi4py</code> installation as well.</p> <p>Installation:</p> <ol> <li> <p>Load the current latest parallel <code>HDF5</code> module (e.g. <code>HDF5/1.10.6-CrayGNU-20.11-parallel</code>).</p> <pre><code>module load HDF5/1.10.6-CrayGNU-20.11-parallel\n</code></pre> </li> <li> <p>Update environment variables</p> <pre><code>export MPI_DIR=$MPICH_DIR\nexport MPI_INCLUDE=$MPICH_DIR/include\nexport MPI_LIB=$MPICH_DIR/lib\nexport LB_LIBRARY_PATH=$MPI_DIR/lib:$LD_LIBRARY_PATH\nexport MPICC=CC\nexport mpicc=CC\n\nexport HDF5_MPI=\"ON\"\nexport HDF5_DIR=/apps/daint/UES/jenkins/7.0.UP02-20.11/gpu/easybuild/software/HDF5/1.10.6-CrayGNU-20.11-parallel\n</code></pre> </li> <li> <p>Install h5py from source.</p> <p>a. Clone repo locally:</p> <pre><code>git clone https://github.com/h5py/h5py\n</code></pre> <p>b. Update the <code>setup_build.py</code> file with the additional following <code>include_dirs</code>:</p> <pre><code>settings['include_dirs'] += ['/opt/cray/pe/mpt/7.7.16/gni/mpich-gnu/8.2/include/']\n</code></pre> <p>c. Install from locally using <code>pip</code>:</p> <pre><code>pip install .\n</code></pre> </li> </ol> <p>Testing:</p> <p>Test h5py parallel build using following example script (<code>parallel_h5py.py</code>):</p> <pre><code>from mpi4py import MPI\nimport h5py\n\ncomm = MPI.COMM_WORLD\nrank = comm.rank\nsize = comm.size\n\nf = h5py.File('parallel_test.hdf5', 'w', driver='mpio', comm=MPI.COMM_WORLD)\n\ndset = f.create_dataset('test', (size,), dtype='i')\ndset[rank] = rank\n\nf.close()\n</code></pre> <ol> <li> <p>Load system <code>HDF5/xxx-parallel</code> and your custom python environment with <code>h5py</code> and <code>mpi4py</code>. Run <code>parallel_h5py.py</code> script:</p> <pre><code>srun python parallel_h5py.py\n</code></pre> </li> <li> <p>Inspect output:</p> <pre><code>h5dump parallel_test.h5\n</code></pre> </li> </ol>"},{"location":"blog/HPC/2021-10-27-slurm/","title":"Slurm: Usage guide for HPC Job Scheduler","text":"<p>Last updated: October 27, 2021</p>"},{"location":"blog/HPC/2021-10-27-slurm/#administrative-commands","title":"Administrative commands","text":"<ul> <li> <p>Change the state of <code>node02</code>:</p> <pre><code>scontrol update nodename=node02 state=resume\n</code></pre> </li> <li> <p>Show partitions, nodes</p> <pre><code>scontrol show partition\nscontrol show nodes\n</code></pre> </li> <li> <p>Show status of slurm</p> <pre><code>sinfo\n</code></pre> </li> <li> <p>Report only down, drained of draining nodes and their reason</p> <pre><code>sinfo -R\n</code></pre> </li> </ul>"},{"location":"blog/HPC/2021-10-27-slurm/#user-commands","title":"User commands","text":"<ul> <li> <p>Run one task on a given partition with 3 nodes</p> <pre><code>srun --nodes=3 --partition=cluster hostname\n</code></pre> </li> <li> <p>Run one task on a specific node list</p> <pre><code>srun --nodelist=node01,node02 hostname\n</code></pre> </li> <li> <p>Run multiple task on a single node</p> <pre><code>srun --ntasks-per-node=4 hostname\n</code></pre> </li> <li> <p>Submit a batch job</p> <pre><code>sbatch submit.job\n</code></pre> </li> </ul> <p>Contents of of the <code>submit.job</code></p> <pre><code>#!/bin/bash\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=4\n#SBATCH --partition=cluster\n\ncd $SLURM_SUBMIT_DIR\n\nsrun echo \"Hello, World!\"\n</code></pre>"},{"location":"blog/HPC/2022-02-09-benchmarking/","title":"A guide on basic benchmarking","text":"<p>Last updated: February 9, 2022</p>"},{"location":"blog/HPC/2022-02-09-benchmarking/#storage","title":"Storage","text":"<ul> <li> <p>Perform timings of device/cache reads on device (<code>sda</code>):</p> <pre><code>hparm -tT /dev/sda\n</code></pre> </li> <li> <p>Measure the write performance of a disk</p> <pre><code>dd if=/dev/zero of=file_1GB bs=1024 count=1000000 conv=fdatasync\n</code></pre> </li> <li> <p>Benchmark with IOzone filesystem benchmarking tool and export to <code>xls</code></p> <pre><code>iozone -a /dev/sdb1 -b results.xls\n</code></pre> </li> </ul>"},{"location":"blog/HPC/2022-02-09-benchmarking/#network","title":"Network","text":"<ul> <li> <p>Testing internet bandwidth</p> <pre><code>speedtest-cli\n</code></pre> </li> <li> <p>Measuring bandwidth between two computer:</p> <ul> <li> <p>Server-side (default port: <code>5001</code>):</p> <pre><code>iperf -s\n</code></pre> </li> <li> <p>Client-side:</p> <pre><code>iperf -c server_ip\n</code></pre> </li> </ul> </li> </ul>"},{"location":"blog/HPC/2022-06-01-blender/","title":"Blender rendering using SLURM","text":"<p>Last updated: June 1, 2022</p>"},{"location":"blog/HPC/2022-06-01-blender/#slurm-submission-python-script","title":"SLURM submission python script","text":"<ul> <li>Distributes frames of render animation to multiple nodes.</li> <li>Rendering <code>donut.blend</code> from frame <code>1</code> to <code>300</code>.</li> <li>Each node rendering <code>60</code> frames.</li> <li>Blender bin path: <code>BLENDER_PATH=/store/empa/em13/apps/blender</code>.</li> </ul> <p>Contents of <code>submit.py</code>: <pre><code>#!/usr/bin/env python3\nimport os\n\n# Constants\njob_name = \"blender\"\ntime = \"00:30:00\"\naccount = \"em13\"\npartition = \"normal\"\nbackground = \"donut.blend\"\nframe_start = 1\nframe_end = 300\nnframes_per_node = 60\n\nHEADER=\\\nf\"\"\"#!/bin/bash -l\n#SBATCH --time={time}\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-core=2\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=24\n#SBATCH --constraint=gpu\n#SBATCH --hint=multithread\n#SBATCH --account={account}\n#SBATCH --partition={partition}\n\nmodule load daint-gpu\nmodule load cudatoolkit\n\n# NCCL FLAGS\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nexport PYTHONFAULTHANDLER=1\n\nBLENDER_PATH=/store/empa/em13/apps/blender\nBACKGROUND={background}\n\"\"\"\n\n# Batch split\nfor batch_start, batch_end in zip(\n        range(frame_start, frame_end, nframes_per_node),\n        range(frame_start + nframes_per_node - 1, frame_end + nframes_per_node - 1, nframes_per_node)\n        ):\n    # Write submission script\n    with open(\"batch.job\", \"w\") as f:\n        f.writelines(HEADER)\n        f.write(\"srun $BLENDER_PATH/blender \\\\\\n\")\n        f.write(\"\\t--python $BLENDER_PATH/enable_cuda.py \\\\\\n\")\n        f.write(\"\\t--background $BACKGROUND \\\\\\n\")\n        f.write(\"\\t--render-output //render/frame_###.png \\\\\\n\")\n        f.write(f\"\\t--frame-start {batch_start} \\\\\\n\")\n        f.write(f\"\\t--frame-end {batch_end} \\\\\\n\")\n        f.write(\"\\t--render-anim\\n\")\n\n    # Submit job\n    os.system(f\"sbatch --job-name={job_name}-s{batch_start:03d}-e{batch_end:03d} batch.job\")\n\n# Cleanup\nos.remove(\"batch.job\")\n</code></pre></p>"},{"location":"blog/HPC/2022-06-01-blender/#ensuring-cuda-is-enables-on-the-nodes","title":"Ensuring cuda is enables on the nodes","text":"<p>Contents of <code>enable_cuda.py</code>: <pre><code>import bpy\n\ndef enable_gpus(device_type, use_cpus=False):\n    preferences = bpy.context.preferences\n    cycles_preferences = preferences.addons[\"cycles\"].preferences\n    cycles_preferences.refresh_devices()\n    devices = cycles_preferences.devices\n\n    if not devices:\n        raise RuntimeError(\"Unsupported device type\")\n\n    activated_gpus = []\n    for device in devices:\n        if device.type == \"CPU\":\n            device.use = use_cpus\n        else:\n            device.use = True\n            activated_gpus.append(device.name)\n            print('activated gpu', device.name)\n\n    cycles_preferences.compute_device_type = device_type\n    bpy.context.scene.cycles.device = \"GPU\"\n\n    return activated_gpus\n\nenable_gpus(\"CUDA\")\n</code></pre></p>"},{"location":"blog/HPC/2022-10-17-setup-jupyterhub/","title":"A guide to setup jupyterhub","text":"<p>References:</p> <ul> <li>https://jupyterhub.readthedocs.io/en/stable/quickstart.html#installation.</li> <li>https://github.com/markusschanta/awesome-jupyter#jupyterlab-extensions</li> </ul>"},{"location":"blog/HPC/2022-10-17-setup-jupyterhub/#install-jupyterhub","title":"Install <code>jupyterhub</code>","text":"<ol> <li> <p>Setup jupyterhub in conda environment. This is the simplest option from experience.</p> <pre><code>conda install -c conda-forge jupyterhub  # installs jupyterhub and proxy\nconda install jupyterlab notebook  # needed if running the notebook servers in the same environmen\n</code></pre> </li> <li> <p>Install any additional libraries (eg.: <code>numpy</code>, <code>cudatoolkit</code>, <code>MATLAB</code>)</p> <pre><code>conda install -c nvidia cuda\npython -m pip install numpy scipy matplotlib # basic numerical libraries\npython -m pip install jupyter-matlab-proxy # matlab (assuming matlab is available locally)\njupyter labextension install @jupyterlab/server-proxy\n</code></pre> </li> <li> <p>Install extensions for <code>jupyterlab</code>:</p> <pre><code>pip install JLDracula # dracula theme\npip install jupyterlab_nvdashboard # GPU dashboard\npip install jupyterlab-drawio # drawing diagrams\npip install nb_black # linting\npip install jupyterlab-code-formatter # formatting\n</code></pre> </li> </ol>"},{"location":"blog/HPC/2022-10-17-setup-jupyterhub/#create-a-startup-script-for-jupyterhub","title":"Create a startup script for <code>jupyterhub</code>","text":"<p>A nice startup script for starting jupyterhub:</p> <p>Contents of <code>/etc/jupyterhub/start_jupyterhub.sh</code>: <pre><code>#!/bin/env bash\n\nexport PYTHONPATH=''\neval \"$(/opt/conda/condabin/conda shell.bash hook)\"\n\nconda activate jupyterhub\n\njupyterhub -f jupyterhub_config.py\n</code></pre></p> <p>We can add additional bash config that might be needed for setting up the jupyter environment.</p>"},{"location":"blog/HPC/2022-10-17-setup-jupyterhub/#create-a-systemd-unit-for-jupyterhub","title":"Create a <code>systemd</code> unit for jupyterhub","text":"<p>Now to ensure that jupyterhub is started as system boot, we can add it as a <code>systemd</code> unit which will call the bash script above.</p> <p>Contents of <code>/etc/systemd/system/jupyterhub.service</code>: <pre><code>[Unit]\nDescription=JupyterHub\nAfter=syslog.target network-online.target nginx.target sshd.target\n\n[Service]\nUser=root\nWorkingDirectory=/etc/jupyterhub\nEnvironment=\"PATH=/opt/conda/condabin:$PATH\"\nExecStart=/etc/jupyterhub/start_jupyterhub.sh\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p> <p>We can enabled and start the following systemd unit by: <pre><code>systemctl daemon-reload\nsystemctl enable jupyterhub.service\nsystemctl start jupyterhub.service\n</code></pre></p> <p>Now, upon boot, a <code>jupyterhub</code> service will automatically started with jupyterhub served at default port (e.g.: <code>http://localhost:8880</code>).</p>"},{"location":"blog/HPC/2022-10-17-setup-jupyterhub/#setup-reverse-proxy-using-nginx","title":"Setup reverse-proxy using <code>nginx</code>","text":"<p>It is still inconvenient to remember the port number. So it would be nice to have <code>jupyterhub</code> accessible at some subdomain or subdirectory (e.g.: <code>http://localhost/jupyter</code>). We can achieve this by using a reverse-proxy such as <code>nginx</code>.</p> <p>Contents of <code>/etc/nginx/sites-available/default</code>:</p> <pre><code>server {\n...\n\n    ## &gt;&gt;&gt; Append this below\n\n# JupyterHub\nlocation /jupyter/ {\n# NOTE important to also set base url of jupyterhub to /jupyter in its config\nproxy_pass http://127.0.0.1:8880;\n\nproxy_redirect   off;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header Host $host;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto $scheme;\n\n# websocket headers\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection $connection_upgrade;\n\n}\n</code></pre> <p>We can update the nginx using following commands: <pre><code>nginx -t # Test the configuration\nnginx -s reload # Reload the configuration\n</code></pre></p> <p>Now we should have jupyterhub served at: <code>http://localhost/jupyter</code>. If we have port exposed to outside, then <code>http://&lt;your_hostname&gt;/jupyter</code>.</p>"},{"location":"blog/ML/2020-12-01-linear-regression/","title":"Linear regression in PyTorch","text":"<p>Linear regression</p> <p>Given a data set $\\{y_i, x_i\\}_{i=1}^n$ of $n$ statistical units, we have the following relationship:</p> $$ y_i = \\theta_1 x_i + \\theta_0 + \\varepsilon_i, \\qquad i=1,\\ldots, n,$$<p>where:</p> <ul> <li>$y_i$ is observed value (dependent variable</li> <li>$x_i$ is the independent variable</li> <li>$\\theta_1$ and $\\theta_0$ are model parameters</li> <li>$\\varepsilon_i$ is the measurement error</li> </ul> <p>Table of Content</p> <ol> <li>Setup environment</li> <li>Define the model, loss function and optimizer</li> <li>Train the model</li> <li>Predict and evaluate the model</li> <li>Save the trained model</li> <li>Load pretrained model</li> </ol> <p></p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim\n</pre> import numpy as np import matplotlib as mpl import matplotlib.pyplot as plt  import torch import torch.nn as nn import torch.optim In\u00a0[2]: Copied! <pre>mpl.style.use('seaborn-poster')\nmpl.rcParams['mathtext.fontset'] = 'cm'\nmpl.rcParams['figure.figsize'] = 5 * np.array([1.618033988749895, 1])\n</pre> mpl.style.use('seaborn-poster') mpl.rcParams['mathtext.fontset'] = 'cm' mpl.rcParams['figure.figsize'] = 5 * np.array([1.618033988749895, 1]) In\u00a0[3]: Copied! <pre># Reproducibility\nseed = 234\nnp.random.seed(seed)\ntorch.random.manual_seed(seed);\n</pre> # Reproducibility seed = 234 np.random.seed(seed) torch.random.manual_seed(seed); In\u00a0[4]: Copied! <pre>n = 500\ntheta_1 = 2.0\ntheta_0 = 0.4\neps_std = 0.2\n</pre> n = 500 theta_1 = 2.0 theta_0 = 0.4 eps_std = 0.2 In\u00a0[5]: Copied! <pre>x_train = np.random.rand(n,1)-0.5\neps = np.random.normal(scale=eps_std, size=(n,1))\ny_train = x_train*theta_1 + theta_0 + eps\n</pre> x_train = np.random.rand(n,1)-0.5 eps = np.random.normal(scale=eps_std, size=(n,1)) y_train = x_train*theta_1 + theta_0 + eps In\u00a0[6]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x_train, y_train, 'k.', label='observations')\nax.plot(x_train, x_train*theta_1 + theta_0, 'tab:gray', lw=5,\n        label=r'analytical ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(theta_1, theta_0))\nax.set(xlabel='$x$', ylabel='$y$', xlim=(-0.52,0.52), ylim=(-1.0, 1.5));\n# ax.legend();\nfig.legend(loc='right', bbox_to_anchor=(1.5, 0.6));\n</pre> fig, ax = plt.subplots() ax.plot(x_train, y_train, 'k.', label='observations') ax.plot(x_train, x_train*theta_1 + theta_0, 'tab:gray', lw=5,         label=r'analytical ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(theta_1, theta_0)) ax.set(xlabel='$x$', ylabel='$y$', xlim=(-0.52,0.52), ylim=(-1.0, 1.5)); # ax.legend(); fig.legend(loc='right', bbox_to_anchor=(1.5, 0.6)); <p></p> In\u00a0[7]: Copied! <pre>n_features = 1 # number of nodes (1 weight + 1 bias)\nnum_epochs = 150 # i.e. number of iterations\nlearning_rate = 0.2\n</pre> n_features = 1 # number of nodes (1 weight + 1 bias) num_epochs = 150 # i.e. number of iterations learning_rate = 0.2 In\u00a0[8]: Copied! <pre># Linear regression model\nmodel = nn.Linear(in_features=n_features, out_features=n_features)\nmodel\n</pre> # Linear regression model model = nn.Linear(in_features=n_features, out_features=n_features) model Out[8]: <pre>Linear(in_features=1, out_features=1, bias=True)</pre> In\u00a0[9]: Copied! <pre>for i, (name, param) in enumerate(model.named_parameters()):\n    print(r\"{:6s} (theta_{}): {:.4f}\".format(name, 1-i, param.item()))\n</pre> for i, (name, param) in enumerate(model.named_parameters()):     print(r\"{:6s} (theta_{}): {:.4f}\".format(name, 1-i, param.item())) <pre>weight (theta_1): 0.8553\nbias   (theta_0): 0.1633\n</pre> In\u00a0[10]: Copied! <pre># Loss and optimizer\ncriterion = nn.L1Loss() # L^1-norm, aka. mean absolute error loss\ncriterion\n</pre> # Loss and optimizer criterion = nn.L1Loss() # L^1-norm, aka. mean absolute error loss criterion Out[10]: <pre>L1Loss()</pre> In\u00a0[11]: Copied! <pre>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # Stochastic gradient-descent\noptimizer\n</pre> optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # Stochastic gradient-descent optimizer Out[11]: <pre>SGD (\nParameter Group 0\n    dampening: 0\n    lr: 0.2\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)</pre> <p></p> In\u00a0[12]: Copied! <pre>history = dict(loss=[], parameters=[], grads=[])\nfor epoch in range(num_epochs):\n    # 1. Convert numpy arrays to torch tensors\n    x = torch.from_numpy(x_train.astype('float32'))\n    y = torch.from_numpy(y_train.astype('float32'))\n\n    # 2. Forward-pass:\n    y_hat = model(x) # prediction step\n    \n    # 3. Calculate loss\n    loss = criterion(y_hat, y)\n    \n    # 4. Backward propagation \n    optimizer.zero_grad() # reset gradients to zero\n    loss.backward() # backprop: calculate gradients w.r.t to loss\n    \n    # 5. Update weights\n    optimizer.step() # update gradient\n    \n    # 6. Log\n    history['loss'].append(loss.item())\n    history['parameters'].append([param.detach().item() for param in model.parameters()])\n    history['grads'].append([param.grad.detach().item() for param in model.parameters()])\n    if (epoch % 10) == 0 or epoch==(num_epochs-1):\n        print('[Epoch {:3d}]: loss={:.4f}, w={:.2f}, b={:.2f}'.format(\n            epoch, history['loss'][-1], *history['parameters'][-1]))\n</pre> history = dict(loss=[], parameters=[], grads=[]) for epoch in range(num_epochs):     # 1. Convert numpy arrays to torch tensors     x = torch.from_numpy(x_train.astype('float32'))     y = torch.from_numpy(y_train.astype('float32'))      # 2. Forward-pass:     y_hat = model(x) # prediction step          # 3. Calculate loss     loss = criterion(y_hat, y)          # 4. Backward propagation      optimizer.zero_grad() # reset gradients to zero     loss.backward() # backprop: calculate gradients w.r.t to loss          # 5. Update weights     optimizer.step() # update gradient          # 6. Log     history['loss'].append(loss.item())     history['parameters'].append([param.detach().item() for param in model.parameters()])     history['grads'].append([param.grad.detach().item() for param in model.parameters()])     if (epoch % 10) == 0 or epoch==(num_epochs-1):         print('[Epoch {:3d}]: loss={:.4f}, w={:.2f}, b={:.2f}'.format(             epoch, history['loss'][-1], *history['parameters'][-1])) <pre>[Epoch   0]: loss=0.3869, w=0.89, b=0.26\n[Epoch  10]: loss=0.2384, w=1.31, b=0.42\n[Epoch  20]: loss=0.1822, w=1.63, b=0.40\n[Epoch  30]: loss=0.1639, w=1.81, b=0.40\n[Epoch  40]: loss=0.1591, w=1.90, b=0.40\n[Epoch  50]: loss=0.1579, w=1.94, b=0.40\n[Epoch  60]: loss=0.1575, w=1.97, b=0.40\n[Epoch  70]: loss=0.1573, w=1.99, b=0.40\n[Epoch  80]: loss=0.1572, w=2.00, b=0.40\n[Epoch  90]: loss=0.1572, w=2.01, b=0.40\n[Epoch 100]: loss=0.1571, w=2.02, b=0.40\n[Epoch 110]: loss=0.1571, w=2.03, b=0.40\n[Epoch 120]: loss=0.1571, w=2.03, b=0.40\n[Epoch 130]: loss=0.1571, w=2.04, b=0.40\n[Epoch 140]: loss=0.1571, w=2.04, b=0.40\n[Epoch 149]: loss=0.1571, w=2.04, b=0.40\n</pre> In\u00a0[13]: Copied! <pre>fig, axes = plt.subplots(1, 2, figsize=(mpl.rcParams['figure.figsize'][0]*2, mpl.rcParams['figure.figsize'][1]))\n\naxes[0].plot(history['loss'])\naxes[0].set(xlabel='epoch', ylabel='$L^1$ loss',\n       title='Training loss history');\n\naxes[1].plot(history['grads'])\naxes[1].set(xlabel='epoch', ylabel='gradients',\n            title='Training gradient history');\naxes[1].legend([r'$\\nabla w \\equiv \\nabla \\theta_1$',\n                r'$\\nabla b \\equiv \\nabla \\theta_0$'])\n</pre> fig, axes = plt.subplots(1, 2, figsize=(mpl.rcParams['figure.figsize'][0]*2, mpl.rcParams['figure.figsize'][1]))  axes[0].plot(history['loss']) axes[0].set(xlabel='epoch', ylabel='$L^1$ loss',        title='Training loss history');  axes[1].plot(history['grads']) axes[1].set(xlabel='epoch', ylabel='gradients',             title='Training gradient history'); axes[1].legend([r'$\\nabla w \\equiv \\nabla \\theta_1$',                 r'$\\nabla b \\equiv \\nabla \\theta_0$']) Out[13]: <pre>&lt;matplotlib.legend.Legend at 0x7f89b09c0ac0&gt;</pre> In\u00a0[14]: Copied! <pre># L^1 norm: numpy version\nl1_norm = lambda y_hat, y: np.abs(y_hat - y).mean(axis=0)\n\n# Loss landscape\ntheta_1_h, theta_0_h = np.meshgrid(np.linspace(0, 4),\n                                 np.linspace(-0.2, 0.8))\nloss_surface = l1_norm(x_train[...,None]*theta_1_h[None] + theta_0_h[None],\n                       y_train[...,None])\n</pre> # L^1 norm: numpy version l1_norm = lambda y_hat, y: np.abs(y_hat - y).mean(axis=0)  # Loss landscape theta_1_h, theta_0_h = np.meshgrid(np.linspace(0, 4),                                  np.linspace(-0.2, 0.8)) loss_surface = l1_norm(x_train[...,None]*theta_1_h[None] + theta_0_h[None],                        y_train[...,None]) In\u00a0[15]: Copied! <pre>fig, ax = plt.subplots()\nim = ax.contourf(theta_1_h, theta_0_h, loss_surface)\nax.plot(*history['parameters'][0], 'c.', ms=15, label='start', zorder=10)\nax.plot(theta_1, theta_0, 'r.', ms=20, label='optima', zorder=10)\nax.plot(np.array(history['parameters'])[:,0],\n        np.array(history['parameters'])[:,1],\n        '.-', c='k', label='path')\nax.set(xlabel=r'$\\theta_1$ ($w$, weight)',\n       ylabel=r'$\\theta_0$ ($b$, bias)',\n       title='$L^1$ loss landscape')\nfig.colorbar(im, ax=ax)\nfig.legend(loc='right', bbox_to_anchor=(1.15, 0.7));\n</pre> fig, ax = plt.subplots() im = ax.contourf(theta_1_h, theta_0_h, loss_surface) ax.plot(*history['parameters'][0], 'c.', ms=15, label='start', zorder=10) ax.plot(theta_1, theta_0, 'r.', ms=20, label='optima', zorder=10) ax.plot(np.array(history['parameters'])[:,0],         np.array(history['parameters'])[:,1],         '.-', c='k', label='path') ax.set(xlabel=r'$\\theta_1$ ($w$, weight)',        ylabel=r'$\\theta_0$ ($b$, bias)',        title='$L^1$ loss landscape') fig.colorbar(im, ax=ax) fig.legend(loc='right', bbox_to_anchor=(1.15, 0.7)); <p></p> In\u00a0[16]: Copied! <pre># Predict\npredict = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n\n# Plot the graph\nfig, ax = plt.subplots()\nax.plot(x_train, y_train, 'k.', label='observations')\nax.plot(x_train, x_train*theta_1 + theta_0, 'tab:gray', lw=5,\n        label=r'analytical: ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(theta_1, theta_0))\nax.plot(x_train, x_train*history['parameters'][0][0] + history['parameters'][0][1], 'tab:blue',\n        label=r'prediction [epoch 0]: ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(*history['parameters'][0]))\nax.plot(x_train, predict, 'tab:red',\n        label=r'prediction [trained]: ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(*history['parameters'][-1]))\nax.set(xlabel='$x$', ylabel='$y$',\n       title='Training accuracy',\n       xlim=(-0.52,0.52), ylim=(-1.0, 1.5))\n\nfig.legend(loc='right', bbox_to_anchor=(1.6, 0.6));\n</pre> # Predict predict = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()  # Plot the graph fig, ax = plt.subplots() ax.plot(x_train, y_train, 'k.', label='observations') ax.plot(x_train, x_train*theta_1 + theta_0, 'tab:gray', lw=5,         label=r'analytical: ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(theta_1, theta_0)) ax.plot(x_train, x_train*history['parameters'][0][0] + history['parameters'][0][1], 'tab:blue',         label=r'prediction [epoch 0]: ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(*history['parameters'][0])) ax.plot(x_train, predict, 'tab:red',         label=r'prediction [trained]: ($\\theta_1={:.2f}$, $\\theta_0={:.2f}$)'.format(*history['parameters'][-1])) ax.set(xlabel='$x$', ylabel='$y$',        title='Training accuracy',        xlim=(-0.52,0.52), ylim=(-1.0, 1.5))  fig.legend(loc='right', bbox_to_anchor=(1.6, 0.6)); <p></p> In\u00a0[17]: Copied! <pre># Save the model checkpoint\ntorch.save(model.state_dict(), 'model.ckpt')\n</pre> # Save the model checkpoint torch.save(model.state_dict(), 'model.ckpt') <p></p> In\u00a0[18]: Copied! <pre>checkpoint = torch.load('model.ckpt')\ncheckpoint\n</pre> checkpoint = torch.load('model.ckpt') checkpoint Out[18]: <pre>OrderedDict([('weight', tensor([[2.0430]])), ('bias', tensor([0.4025]))])</pre> In\u00a0[19]: Copied! <pre>model.load_state_dict(checkpoint)\n</pre> model.load_state_dict(checkpoint) Out[19]: <pre>&lt;All keys matched successfully&gt;</pre>"},{"location":"blog/ML/2020-12-01-linear-regression/#linear-regression-in-pytorch","title":"Linear regression in PyTorch\u00b6","text":"<p>Last updated: December 1, 2020</p> <p></p> <p>References</p> <ul> <li>https://pytorch.org/</li> <li>https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/linear_regression/main.py</li> <li>https://en.wikipedia.org/wiki/Linear_regression</li> <li>https://en.wikipedia.org/wiki/Backpropagation</li> <li>https://en.wikipedia.org/wiki/Stochastic_gradient_descent</li> </ul>"},{"location":"blog/ML/2020-12-01-linear-regression/#1-setup-environment","title":"1. Setup environment\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#load-packages-modules","title":"Load packages / modules\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#generate-training-dataset","title":"Generate training dataset\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#2-define-the-model-loss-function-and-optimizer","title":"2. Define the model, loss function and optimizer\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#hyperparameters","title":"Hyperparameters\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#model","title":"Model\u00b6","text":"$$ \\mathcal{F}(x;\\ \\theta): x \\rightarrow y $$<p>Linear 1-D model:</p> $$ \\mathcal{F}(x;\\ \\theta) = w x + b = \\hat{y}$$<p>where:</p> <ul> <li>$y$ is the ground truth</li> <li>$\\hat{y}$ is the predicted output</li> <li>$\\theta$ are the trainable parameters, with<ul> <li>$w$ is the learnable weight, i.e. $w \\equiv \\theta_1$</li> <li>$b$ is the learnable bias, i.e. $b \\equiv \\theta_0$</li> </ul> </li> </ul>"},{"location":"blog/ML/2020-12-01-linear-regression/#loss-function","title":"Loss function\u00b6","text":"<p>$L^1$-norm:</p> $$ \\mathcal{L}(\\hat{Y}, Y;\\ \\theta) = \\textrm{mean} \\left( \\{l_1,\\dots,l_N\\}^\\top \\right), \\quad l_n = \\left| \\hat{y}_n - y_n \\right| $$<p>where:</p> <ul> <li>$X \\in \\mathbb{R}^N$ is the input matrix</li> <li>$Y \\in \\mathbb{R}^N$ is the ground truth matrix</li> <li>$N$ is the batch size (for now, batch size = number of examples)</li> </ul>"},{"location":"blog/ML/2020-12-01-linear-regression/#optimizer","title":"Optimizer\u00b6","text":"<p>Stochastic gradient descent</p> $$ \\theta^{n+1} = \\theta^n - \\eta \\nabla \\mathcal{L}(\\theta^n) $$<p>where:</p> <ul> <li>$\\eta$ is the learning rate (i.e. step size)</li> </ul>"},{"location":"blog/ML/2020-12-01-linear-regression/#3-train-the-model","title":"3. Train the model\u00b6","text":"$$ \\mathcal{F}^* = \\arg \\min_{\\mathcal{F}}\\ \\mathcal{L}(\\hat{Y}, Y;\\ \\theta)$$<p>Algorithm:</p> <ol> <li>Convert data to torch tensor: <code>torch.from_numpy(...)</code></li> <li>Forward pass: <code>y_hat = model(x)</code></li> <li>Calculate loss: <code>loss = criterion(y_hat, y)</code></li> <li>Compute gradients: <code>loss.backward()</code></li> <li>Update weights: <code>optimizer.step()</code></li> </ol>"},{"location":"blog/ML/2020-12-01-linear-regression/#training-loss-history","title":"Training loss history\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#optimization-over-the-loss-landscape","title":"Optimization over the loss landscape\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#4-predict-and-evaluate-the-model","title":"4. Predict and evaluate the model\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#training-accuracy","title":"Training accuracy\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#5-save-the-trained-model","title":"5. Save the trained model\u00b6","text":""},{"location":"blog/ML/2020-12-01-linear-regression/#6-load-pretrained-model","title":"6. Load pretrained model\u00b6","text":""},{"location":"blog/linux/2021-05-01-arch-linux/","title":"Arch Linux installation guide","text":"<p>Last updated: May 1, 2021</p> <p>The installation guide below is a summarized version of the official Installation Guide.</p>"},{"location":"blog/linux/2021-05-01-arch-linux/#installing-basic-system","title":"Installing basic system","text":"<ol> <li> <p>Choose correct keyboard keymaps</p> <pre><code>loadkeys keymap\n</code></pre> </li> <li> <p>Assert boot mode</p> <pre><code>ls /sys/firmware/efi/efivars\n</code></pre> </li> <li> <p>Make sure internet connection is present</p> <pre><code>ping 8.8.8.8\n</code></pre> </li> <li> <p>Set correct system time</p> <pre><code>timedatectl set-ntp true\n</code></pre> </li> <li> <p>Partition the disks</p> <ol> <li> <p>List disks using <code>fdisk</code></p> <pre><code>fdisk -l\n</code></pre> </li> <li> <p>If UEFI is present, use <code>GPT</code> and make <code>EFI</code> partition, <code>swap</code>, and root <code>/</code></p> <pre><code>cfdisk /dev/sdX # or /dev/nvme0nX\n</code></pre> </li> <li> <p>Set correct size, type and write partition table.</p> </li> </ol> </li> <li> <p>Format the disks</p> <ol> <li> <p>Make <code>EFI</code> partition</p> <pre><code>mkfs.fat -F32 /dev/sdXA # A is EFI partition\n</code></pre> </li> <li> <p>Make swap</p> <pre><code>mkswap /dev/sdXB # B is swap partition\n</code></pre> </li> <li> <p>Turn swap on</p> <pre><code>swapon /dev/sdXB\n</code></pre> </li> <li> <p>Make root fs</p> <pre><code>mkfs.ext4 /dev/sdaXC # C is root partition\n</code></pre> </li> </ol> </li> <li> <p>Mount root partition to <code>mnt</code></p> <pre><code>mount /dev/sdXC /mnt\n</code></pre> </li> <li> <p>Install necessary packages</p> <pre><code>pacstrap /mnt base base-devel linux linux-firmware vim nano man zsh\n</code></pre> </li> <li> <p>Write filesystem table</p> <pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab\n</code></pre> </li> <li> <p>Change root to <code>/mnt</code></p> <pre><code>arch-chroot /mnt\n</code></pre> </li> <li> <p>Set correct time zone</p> <pre><code>ln -sf /usr/share/zoneinfo/Europe/Zurich /etc/localtime\n\nhwclock --systohc\n</code></pre> </li> <li> <p>Set locale</p> <ol> <li> <p>Uncomment the correct locale</p> <pre><code>vim /etc/locale.gen\n</code></pre> </li> <li> <p>Set locale</p> <pre><code>locale-gen\n</code></pre> </li> </ol> </li> <li> <p>Set hostname and hosts</p> <ol> <li> <p>Add your hostname <code>yourhostname</code></p> <pre><code>echo \"yourhostname\" &gt;&gt; /etc/hostname\n</code></pre> </li> <li> <p>Append the following to <code>/etc/hosts</code></p> <pre><code>127.0.0.1   localhost\n::1         localhost\n127.0.1.1   yourhostname.localdomain    yourhostname\n</code></pre> </li> </ol> </li> <li> <p>Setup root password using <code>passwd</code></p> <pre><code>passwd\n</code></pre> </li> <li> <p>Add default users</p> <ol> <li> <p>Add new user</p> <pre><code>useradd -m -s /bin/zsh newuser\n</code></pre> </li> <li> <p>Give new user a password with <code>passwd</code></p> <pre><code>passwd newuser\n</code></pre> </li> <li> <p>Add new user to the <code>wheel</code></p> <pre><code>usermod -aG wheel,audio,video,optical,storage newuser\n</code></pre> </li> <li> <p>Setup <code>sudo</code></p> <pre><code>pacman -S sudo\n</code></pre> </li> <li> <p>Enable <code>wheel</code> with <code>visudo</code></p> <pre><code>visudo\n</code></pre> </li> </ol> </li> <li> <p>Setup grub</p> <ol> <li> <p>Install grub and efi-tools</p> <pre><code>pacman -S grub efibootmgr dosfstoosl os-prober mtools\n</code></pre> </li> <li> <p>Make efi boot directory</p> <pre><code>mkdir /boot/EFI\n</code></pre> </li> <li> <p>Mount efi partition</p> <pre><code>mount /dev/sdXA /boot/EFI\n</code></pre> </li> <li> <p>Install grub (efi) for x86-64</p> <pre><code>grub-install --target=x86_64-efi --bootloader-id=grub_uefi --recheck\n</code></pre> </li> <li> <p>Make grub config file</p> <pre><code>grub-mkconfig -o /boot/grub/grub.cfg\n</code></pre> </li> </ol> </li> <li> <p>Network manager for internet connectivity</p> <pre><code>pacman -S networkmanager\n\nsystectl enable NetworkManager # enable network manager\n</code></pre> </li> <li> <p><code>Optional</code>: Reboot to conclude with bare system setup.</p> <pre><code>exit # now back to iso image\numount -R /mnt\nshutdown now # or reboot\n</code></pre> </li> </ol>"},{"location":"blog/linux/2021-05-01-arch-linux/#configuring-system","title":"Configuring system","text":""},{"location":"blog/linux/2021-05-01-arch-linux/#additional-setup-for-a-complete-system","title":"Additional setup for a complete system","text":"<ol> <li> <p>Install audio</p> <pre><code>pacman -S pulseaudio pulseaudio-alsa\n</code></pre> </li> <li> <p>Install a Graphical user interface; Display server (<code>xorg</code>), display driver (<code>nvidia</code>), desktop environment (<code>gnome</code>), window manager, display manager (<code>gdm</code>).</p> <ol> <li> <p>Install packages</p> <pre><code>pacman -S gnome nvidia # gnome-extra for further applications\n</code></pre> </li> <li> <p>Enable display manager for next reboot</p> <pre><code>systemctl enable gdm.service\n</code></pre> </li> </ol> </li> <li> <p>Additional network tools</p> <pre><code>pacman -S openssh rsync\n</code></pre> </li> <li> <p>Development tools: <code>git</code>, <code>htop</code></p> <pre><code>pacman -S git htop\n</code></pre> </li> <li> <p>Reboot</p> <pre><code>exit # now back to iso image\numount -R /mnt\nshutdown now # or reboot\n</code></pre> </li> </ol>"},{"location":"blog/linux/2021-07-01-gateway/","title":"Using another computer as a gateway","text":"<p>Last updated: July 1, 2021</p> <p> graph LR WAN[WAN] --&gt;|eth0| A[Node A] A --&gt;|eth1| B[Node B]  </p> <ul> <li><code>eth0</code>: WAN (public) (e.g., <code>enp0s25</code>)</li> <li><code>eth1</code>: LAN (private) (e.g., <code>bond0</code>)</li> </ul> <p>Setup for gateway node:</p> <pre><code>$ iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE # enable NAT on eth0\n$ iptables -A FORWARD -i eth1 -o eth0 -j ACCEPT # allow packets from eth1 to go out of eth0\n$ iptables -A FORWARD -i eth0 -o eth1 -m state --state RELATED,ESTABLISHED -j ACCEPT # sent the packets to eth1\n</code></pre> <p>On LAN nodes:</p> <pre><code>route add default gw &lt;ip_of_gateway&gt;\n</code></pre>"},{"location":"blog/linux/2021-10-20-systemd/","title":"How to make a custom systemd service","text":"<p>Last updated: October 20, 2021</p> <p>Basic systemd commands:</p> <ul> <li><code>systemctl status</code>: Show status of all systemd service</li> <li><code>systemctl daemon-reload</code>: Reload systemd if units are modified</li> <li><code>systemctl enable</code>: to enable a new service</li> <li><code>systemctl start</code>: to start a new service</li> <li><code>systemctl restart</code>: to restart a service</li> </ul>"},{"location":"blog/linux/2021-10-20-systemd/#example-service-file","title":"Example service file","text":"<ol> <li> <p>Make new service unit file in <code>/etc/systemd/system/new-service.service</code>:</p> <pre><code>[Unit]\nDescription = Sensai background service\nAfter = network.target\n\n[Service]\nExecStart = /usr/bin/python3 /home/lento/projects/sensai/log.py\nUser = lento\nGroup = lento\n\n[Install]\nWantedBy = default.target\n</code></pre> </li> <li> <p>Reload systemd and enable the service</p> <pre><code>systemctl daemon-reload\nsystemctl enable new-service.service\n</code></pre> </li> <li> <p>Start the new service</p> <pre><code>systemctl start new-service.service\n</code></pre> </li> <li> <p>Inspect the status</p> <pre><code>systectl status new-service.service\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-02-10-homelab/","title":"A Raspberry PI homelab setup","text":"<p>Last updated: February 10, 2022</p>"},{"location":"blog/linux/2022-02-10-homelab/#install-rocky-linux-os","title":"Install Rocky Linux OS","text":"<ol> <li> <p>Download <code>RockyPi</code> Rocky Linux OS from Official Repo</p> <pre><code>wget https://download.rockylinux.org/pub/rocky/8/rockyrpi/aarch64/images/RockyRpi_x.x_xxxxxxxx.img.xz\n</code></pre> </li> <li> <p>Verify checksum of the <code>img.xz</code> with <code>`RockyRpi_x.x_xxxxxxxx.sha256sum</code>:</p> <pre><code>xzcat RockyRpi_x.x_xxxxxxxx.img.xz | sha256sum\n</code></pre> </li> <li> <p>Write image to SD card mounted at <code>/dev/sdX</code>:</p> <pre><code>sudo bash -c \"xzcat RockyRpi_x.x_xxxxxxxx.img.xz &gt; /dev/sdX\"\n</code></pre> </li> <li> <p>Initial login to raspberry pi with password <code>rockylinux</code>:</p> <pre><code>ssh rocky@rockypi\n</code></pre> </li> <li> <p>Grow the SD card partition to max (where <code>/</code> is the <code>3</code>rd partition)</p> <pre><code>growpart /dev/sdX 3\n</code></pre> </li> <li> <p>Resize the fs to max</p> <pre><code>resize2fs /dev/sdX3\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-02-10-homelab/#setup-homelab-using-ansible-playbook-homelab","title":"Setup Homelab using ansible playbook: Homelab","text":"<ol> <li> <p>Important: Make sure to run <code>init</code> first separately, where it will create a default user with <code>sudo</code> privileges. Edit <code>playbook-setup.yml</code> appropriately and use <code>just</code> to run the playbook</p> <pre><code>ansible-playbook --diff -K --vault-password-file pass.key playbook-setup.yml # or: just run\n</code></pre> </li> <li> <p>Run additional setup roles: <code>ssh</code>, <code>timezone</code>, <code>packages</code>, <code>upgrade</code>, <code>dnfautomatic</code>, <code>firewalld</code>:</p> <pre><code>just run\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-02-10-homelab/#deploy-all-the-services-onto-the-raspberry-pi","title":"Deploy all the services onto the raspberry pi","text":"<ol> <li> <p>Install docker using <code>geerlingguy.docker</code>.</p> </li> <li> <p>Configure firewall to allow all ports for the services using <code>firewalld</code> role.</p> </li> <li> <p>Setup up a presistent volume for all the data for the docker containers using <code>fs</code> role.</p> </li> <li> <p>Deploy all the services using roles (<code>portainer</code>, <code>watchtower</code>, <code>pihole</code>, ...)</p> </li> </ol>"},{"location":"blog/linux/2022-03-01-changeid/","title":"Change user id and group id of user","text":"<p>Last Modified: March 1, 2022</p> <p>If you run into an issue where you need to change the user id (<code>uid</code>) and group id (<code>gid</code>) of a user (<code>&lt;user&gt;</code>). Assume you want to change <code>uid:gid</code> from <code>1001:1001</code> (<code>&lt;old_uid&gt;:&lt;old_gid&gt;</code>) to <code>1000:1000</code> (<code>&lt;new_uid&gt;:&lt;new_gid&gt;</code>).</p>"},{"location":"blog/linux/2022-03-01-changeid/#steps-by-step-guide","title":"Steps by step guide","text":"<ol> <li> <p>Login using a different user. If need <code>root</code> user: <code>ssh root@&lt;hostname&gt;</code>.</p> </li> <li> <p>Kill all the process of <code>user</code>. Find all process belonging to <code>&lt;user&gt;</code> using <code>ps</code>:</p> <pre><code>ps aux | grep &lt;user&gt;\n</code></pre> </li> <li> <p>Change <code>uid</code> of <code>&lt;user&gt;</code>:</p> <pre><code>usermod -u &lt;new_uid&gt; &lt;user&gt;\n</code></pre> </li> <li> <p>Change <code>gid</code> of <code>user</code>:</p> <pre><code>groupmod -g &lt;new_gid&gt; &lt;user&gt;\n</code></pre> </li> <li> <p>Change ownership of all files from <code>&lt;old_uid&gt;:&lt;old_gid&gt;</code> to <code>&lt;new_uid&gt;:&lt;new_gid&gt;</code>:</p> <pre><code>find /parent/path/ \\( -uid &lt;old_uid&gt; -o -gid &lt;old_gid&gt; \\) \\\n-exec chown &lt;new_uid&gt;:&lt;new_gid&gt; {} \\;\n</code></pre> <p>Example:</p> <pre><code>find /home/lento \\( -uid 1001 -o -gid 1001 \\) \\\n-exec chown 1000:1000 {} \\;\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-03-04-wifi/","title":"Manage and connect to WIFI","text":"<p>Last updated: March 4, 2022</p>"},{"location":"blog/linux/2022-03-04-wifi/#step-by-step-guide","title":"Step by step guide","text":"<ol> <li> <p>Install required packages <code>wireless-tools</code>, <code>network-manager</code>.</p> </li> <li> <p>Display wireless devices using <code>iwconfig</code>:</p> <pre><code>$ iwconfig\n\nlo        no wireless extensions.\n\neth0      no wireless extensions.\n\nwlan0     IEEE 802.11  ESSID:off/any\n          Mode:Managed  Access Point: Not-Associated\n          Retry short limit:7   RTS thr:off   Fragment thr:off\n          Power Management:on\n</code></pre> </li> <li> <p>Check status of device using <code>ip</code>:</p> <pre><code>$ ip a\n\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\nlink/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\ninet 127.0.0.1/8 scope host lo\n   valid_lft forever preferred_lft forever\ninet6 ::1/128 scope host\n   valid_lft forever preferred_lft forever\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000\nlink/ether b8:27:eb:0d:38:af brd ff:ff:ff:ff:ff:ff\n    inet 192.168.2.126/24 brd 192.168.2.255 scope global dynamic eth0\n       valid_lft 85767sec preferred_lft 85767sec\n    inet6 fe80::ba27:ebff:fe0d:38af/64 scope link\n       valid_lft forever preferred_lft forever\n3: wlan0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000\nlink/ether b8:27:eb:58:6d:fa brd ff:ff:ff:ff:ff:ff\n</code></pre> </li> <li> <p>Set <code>wlan0</code> up using <code>nmcli</code>:</p> <pre><code>$ sudo nmcli radio wifi on\n</code></pre> </li> <li> <p>Check status of wifi:</p> <pre><code>$ nmcli radio wifi\n</code></pre> <p>and</p> <pre><code>$ nmcli dev status\n</code></pre> </li> <li> <p>Scan for wifi:</p> <pre><code>$ nmcli dev wifi list\n\nIN-USE  BSSID              SSID                           MODE   CHAN  RATE        SIGNAL  BARS  SECURITY\n    F0:F7:F9:F7:F3:FC  home_wifi                      Infra  3     270 Mbit/s  100     \u2582\u2584\u2586\u2588  WPA2\n    10:C2:5A:0B:74:70  Fuen6Kli007                    Infra  1     130 Mbit/s  60      \u2582\u2584\u2586_  WPA1 WPA3\n    58:90:43:A5:B9:24  Sunrise_2.4GHz_A5B920          Infra  1     195 Mbit/s  57      \u2582\u2584\u2586_  WPA1 WPA2\n</code></pre> </li> <li> <p>Connect to the wifi network (<code>SSID=home_wifi</code>):</p> <pre><code>$ sudo nmcli --ask dev wifi connect home_wifi\n\nPassword: \u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\nDevice 'wlan0' successfully activated with 'ffffa3ff-ffc0-44ff-9792-2ff39f2affe28'.\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-03-08-systemd-timers/","title":"How to setup a systemd timer","text":"<p>Last updated: March 10, 2022</p> <p>Timers are systemd unit files that can execute commands similar to cron jobs.</p>"},{"location":"blog/linux/2022-03-08-systemd-timers/#example-setup-a-timer-to-notify-if-system-is-up","title":"Example: Setup a timer to notify if system is up","text":"<ol> <li> <p>Setup a notify script to send notification to mattermost:</p> <p><code>/opt/notify/notify_up.sh</code> <pre><code>#!/bin/env bash\n\nWEBHOOK_URL=https://mattermost.myserver.ch/hooks/hookurl\n\ncurl -i -X POST -H 'Content-Type: application/json' -d '{\"text\": \":sparkles: **I am back online** :sparkles: :sunglasses::+1:\"}' $WEBHOOK_URL &gt; /dev/null\n</code></pre></p> </li> <li> <p>Setup a timer unit file</p> <p><code>/usr/lib/systemd/system/notify_up.timer</code> <pre><code>[Unit]\nDescription=Notify server is back online\nWants=network-online.target sshd.service\n\n[Timer]\nOnBootSec=5min\nUnit=notify_up.service\n\n[Install]\nWantedBy=timers.target\n</code></pre></p> </li> <li> <p>Setup the service unit file:</p> <p><code>/usr/lib/systemd/system/notify_up.service</code> <pre><code>[Unit]\nDescription=Notify server is back online\nAfter=network-online.target sshd.service\n\n[Service]\nType=oneshot\nExecStart=/opt/notify/notify_up.sh\n</code></pre></p> </li> <li> <p>Reload systemd:</p> <p><code>systemctl daemon-reload</code></p> </li> <li> <p>Enable and start the timer unit file:</p> <pre><code>systemctl enable notify_up.timer\nsystemctl start notify_up.timer\n</code></pre> </li> <li> <p>Show list of timers:</p> <pre><code>$ systemctl list-timers --all\n\nNEXT                        LEFT          LAST                        PASSED       UNIT                         ACTIVATES\nThu 2022-03-10 15:33:45 CET 30min left    Thu 2022-03-10 14:30:30 CET 32min ago    anacron.timer                anacron.service\nThu 2022-03-10 17:38:57 CET 2h 36min left Wed 2022-03-09 22:18:37 CET 16h ago      apt-daily.timer              apt-daily.service\nThu 2022-03-10 19:00:23 CET 3h 57min left Thu 2022-03-10 09:02:59 CET 5h 59min ago fwupd-refresh.timer          fwupd-refresh.service\nThu 2022-03-10 19:02:13 CET 3h 59min left Thu 2022-03-10 12:39:48 CET 2h 23min ago ua-timer.timer               ua-timer.service\nThu 2022-03-10 23:56:18 CET 8h left       Thu 2022-03-10 06:50:02 CET 8h ago       motd-news.timer              motd-news.service\nFri 2022-03-11 00:00:00 CET 8h left       Thu 2022-03-10 00:00:02 CET 15h ago      logrotate.timer              logrotate.service\nFri 2022-03-11 00:00:00 CET 8h left       Thu 2022-03-10 00:00:02 CET 15h ago      man-db.timer                 man-db.service\nFri 2022-03-11 06:58:28 CET 15h left      Thu 2022-03-10 06:50:38 CET 8h ago       apt-daily-upgrade.timer      apt-daily-upgrade.service\nFri 2022-03-11 10:06:01 CET 19h left      Thu 2022-03-10 10:06:01 CET 4h 56min ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.service\nSun 2022-03-13 03:10:30 CET 2 days left   Sun 2022-03-06 03:10:13 CET 4 days ago   e2scrub_all.timer            e2scrub_all.service\nMon 2022-03-14 00:00:00 CET 3 days left   Mon 2022-03-07 00:00:22 CET 3 days ago   fstrim.timer                 fstrim.service\nn/a                         n/a           Wed 2022-03-09 09:55:24 CET 1 day 5h ago notify_up.timer              notify_up.service\nn/a                         n/a           n/a                         n/a          snapd.snap-repair.timer      snapd.snap-repair.service\nn/a                         n/a           n/a                         n/a          ua-license-check.timer       ua-license-check.service\n\n14 timers listed.\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-10-26-snapshot-backups/","title":"Quick and simple snapshot backuping using rsync","text":"<pre><code>The 3-2-1 rule can aid in the backup process. It states that there should be at least 3 copies of the data, stored on 2 different types of storage media, and one copy should be kept offsite, in a remote location.\n\n- Wikipedia on Backup\n</code></pre> <p>References:</p> <ul> <li>https://en.wikipedia.org/wiki/Backup</li> </ul>"},{"location":"blog/linux/2022-10-26-snapshot-backups/#step-1-make-a-rsync-snapshot","title":"Step 1: Make a rsync snapshot","text":"<p>We first make a snapshot of whatever folder you are interested. In this example, we take a snapshot of the home directory (<code>/home/</code>) to a mounted external device mounted at <code>/mnt/backup</code>.</p> <pre><code>rsync -avhux --delete /home/ /mnt/backup/snap-latest/\n</code></pre> <p>The <code>--delete</code> option is used to ensure it's a literal snapshot and unwanted files are also removed. Ideally, we should periodically and automatically perform this command, e.g. using a <code>cron</code> job. Add the following line by editing the crontab, <code>crontab -e</code>:</p> <pre><code>0 12 * * 6 rsync -avhux --delete --info=stats2 /home/ /mnt/backup/snap-latest/ &gt;/mnt/backup/logs/snap-\"$(date +'\\%Y\\%m\\%d')\".log 2&gt;&amp;1\n</code></pre> <p>We now scheduled it for saturday (i.e., <code>6</code>) at noon and also log the transfer to a log file with a timestamp.</p>"},{"location":"blog/linux/2022-10-26-snapshot-backups/#step-2-make-a-compressed-backup","title":"Step 2: Make a compressed backup","text":"<p>Once, we have a snapshot clone of our <code>/home/</code> dir, we can also periodically make a compressed backup of the snapshot. All we need is to tar and compress the latest snapshot with the timestamp of the snapshot:</p> <pre><code>tar -cvzf /mnt/backup/snap-\"$(date +'\\%Y\\%m\\%d')\".tgz --directory=/mnt/backup/snap-latest/ .\n</code></pre> <p>Ideally, we can now make a backup of the compressed file to another backup device. Like with <code>rsync</code>, we can schedule the compressing and ideally we do it once a month:</p> <pre><code>0 0 1 * * tar -cvzf /mnt/backup/snap-\"$(date +'\\%Y\\%m\\%d')\".tgz --directory=/mnt/backup/snap-latest/ . &gt;/mnt/backup/logs/tar-\"$(date +'\\%Y\\%m\\%d')\".log 2&gt;&amp;1\n</code></pre> <p>We perfom the command again with <code>cron</code>, at first day of the month (<code>1</code>).</p>"},{"location":"blog/linux/2022-11-01-rockylinux/","title":"Installing Rocky Linux 9","text":"<p>A detailed guide on installing rocky linux is available at: docs.rockylinux.org.</p>"},{"location":"blog/linux/2022-11-01-rockylinux/#download-and-verify-iso","title":"Download and verify ISO","text":"<ol> <li> <p>Download using <code>wget</code>:</p> <pre><code>wget https://download.rockylinux.org/pub/rocky/9/isos/x86_64/Rocky-9.0-20220808.0-x86_64-dvd.iso\n</code></pre> </li> <li> <p>Check validity of ISO</p> <pre><code>wget https://download.rockylinux.org/pub/rocky/9.0/isos/x86_64/CHECKSUM\nsha256sum -c CHECKSUM --ignore-missing\n</code></pre> </li> <li> <p>Make bootable USB</p> <pre><code>sudo dd if=/path/to/iso.iso of=/dev/sdX status=progress\n</code></pre> <p>Change <code>/path/to/iso</code> and <code>/dev/sdX</code> appropriately. Use <code>lsblk</code> or <code>diskutil list</code> (macos) to find available drives.</p> </li> </ol>"},{"location":"blog/linux/2022-11-01-rockylinux/#install-os-using-anaconda","title":"Install OS using anaconda","text":"<p>Follow the instructions shown. Setup keyboard, language, drive, softwares, network, hostname, time &amp; date, root password and default user. Make sure to give <code>administrator</code> privileges to default user.</p>"},{"location":"blog/linux/2022-11-01-rockylinux/#installing-graphical-environment-gnome","title":"Installing Graphical environment (Gnome)","text":"<pre><code>sudo dnf group list\nsudo dnf groupinstall \"Workstation\"\nsudo dnf groupinstall \"Server with GUI\"\nsudo systemctl set-default graphical\nsudo reboot\n</code></pre>"},{"location":"blog/linux/2022-11-01-rockylinux/#install-cuda-drivers-and-cudatoolkit","title":"Install CUDA drivers and cudatoolkit","text":"<p>A detailed instruction is available at: cuda-installation-guide-linux.</p> <ol> <li> <p>Install development tools, kernel, libraries</p> <pre><code>sudo dnf config-manager --set-enabled crb # codeready-builder\nsudo dnf group install -y \"Development tools\"\nsudo dnf install epel-release rpmfusion-free-release # extra and free\nsudo dnf install -y kernel-devel kernel-headers\n</code></pre> </li> <li> <p>Instructions from Nvidia Cudatoolkit: developer.nvidia.com/cuda-downloads.</p> <pre><code>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo\nsudo dnf clean all\nsudo dnf -y module install nvidia-driver:latest-dkms\nsudo dnf -y install cuda\n</code></pre> </li> <li> <p>Post-installation setup</p> <p>Append to bash environment:</p> <pre><code>export PATH=/usr/local/cuda-11.8/bin${PATH:+:${PATH}}\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64\\\n                        ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n</code></pre> </li> <li> <p>Install third-party libraries</p> <pre><code>sudo dnf install libX11-devel libXi-devel libXmu-devel make mesa-libGLU-devel freeimage-devel\nsudo dnf --enablerepo=devel install freeglut-devel\n</code></pre> </li> <li> <p>Verify cuda environment</p> <p>Download cuda samples, compile and run <code>deviceQuery</code>.</p> </li> </ol>"},{"location":"blog/linux/2022-11-01-rockylinux/#setup-terminal-environment","title":"Setup terminal environment","text":"<ol> <li> <p>Install zsh</p> <pre><code>sudo dnf install zsh\n</code></pre> </li> <li> <p>(Optional) setup and customizations</p> <ul> <li>ohmyzsh: https://ohmyz.sh/</li> <li>nordtheme: https://www.nordtheme.com/</li> <li>Fira code fonts: https://github.com/tonsky/FiraCode</li> </ul> </li> </ol>"},{"location":"blog/linux/2022-11-01-rockylinux/#install-libraries-apps-tools","title":"Install libraries, apps, tools","text":"<ol> <li> <p>Monitoring apps</p> <pre><code>sudo dnf install htop btop glances\n</code></pre> </li> <li> <p>Build tools</p> <pre><code>sudo dnf install libdrm-devel systemd-devel\nsudo dnf install cmake ncurses-devel git gcc-c++\nsudo dnf install qt5-qtdeclarative\n</code></pre> <p>additional: <pre><code>sudo dnf install gcc make dkms acpid libglvnd-glx libglvnd-opengl libglvnd-devel pkgconfig # programming\n</code></pre></p> </li> <li> <p>Audio/Video dependencies</p> <pre><code>sudo dnf install vlc ffmpeg ffmpeg-devel\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-11-01-rockylinux/#install-popular-apps-using-flatpak","title":"Install popular apps using Flatpak","text":"<ol> <li> <p>Setup <code>FlatHub</code> repo: flathub.org</p> <pre><code>sudo dnf install flatpak\nflatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\nsudo reboot\n</code></pre> </li> <li> <p>Install vscode, spotify, etc.</p> <pre><code>flatpak install flathub com.spotify.Client\nflatpak install flathub com.slack.Slack\nflatpak install flathub us.zoom.Zoom\n</code></pre> </li> </ol>"},{"location":"blog/linux/2022-11-01-rockylinux/#setup-python-environment","title":"Setup python environment","text":"<p>Install a conda environment using mambaforge: github.com/conda-forge/miniforge</p>"},{"location":"blog/linux/2022-11-01-rockylinux/#more-info","title":"More info","text":"<ul> <li>CRB: (CRB is \"Code Ready Builder\" - PowerTools was a carryover from CentOS, which is still the equivalent of CRB in RHEL. crb will be the repository name going forward in Rocky Linux and other derivatives.) More info</li> </ul> <p>Additional resources:</p> <ul> <li>https://www.linuxcapable.com/how-to-install-ffmpeg-on-rocky-linux-9/</li> <li>https://medium.com/@panda1100/setup-nvidia-gpu-driver-on-rocky-linux-9-0-166d7ce111b2A</li> <li>https://darryldias.me/2021/nvidia-drivers-on-rocky-linux/</li> <li>https://www.if-not-true-then-false.com/2021/install-nvidia-drivers-on-centos-rhel-rocky-linux/</li> </ul>"}]}